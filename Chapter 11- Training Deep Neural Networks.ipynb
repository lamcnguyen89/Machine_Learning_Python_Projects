{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEMCAYAAAAidwoiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3wURf/A8c+kV4FACIYqUoMQQEA6oSlIiXTpiIqA6MMPrCBIUVAeqg1FxShIkaYUQfIAkV4CEpAWSoCEhBJCCOnl5vfHHiGXXELKJXdJ5v167Su53bmd720u+92dnZ0VUkoURVGU0snK3AEoiqIo5qOSgKIoSimmkoCiKEopppKAoihKKaaSgKIoSimmkoCiKEopppJAKSOECBBCfGXuOCB3sQgh/hVCzCiikDLW6yeE2FoE9fgIIaQQokIR1DVGCHFdCKEzxzbNFMsoIUSsOWNQNELdJ1ByCCHcgZnAi8CTQDTwL/CZlNJfX8YNSJFSPjBboHq5iUUI8S+wXko5o5Bi8AH2AO5SysgM88ug/X9Em7Cuq8BXUsr5GebZAW7ALVmI/4xCiHLAbWASsB54IKUskp2wEEICA6SU6zPMcwRcpZS3iyIGJXs25g5AMakNgBPwKnAJqAh0AMo/LCCljDJPaFlZUiyZSSnvF1E9ycDNIqiqOtr/+1YpZUQR1JcjKWUCkGDuOBRASqmmEjABZQEJdHlMuQC0o9GHrz2AzWj/kNeAV9DOHmZkKCOBccAfQDwQDHQEqgB/AXHASaBpprr6AqeBJCAUmIr+7DObWCrq63gYy+jMsRj5PE/r33NTH8cJoGemMnbAHP06k4ArwNtADf1nyzj56d/jh7bDBBgD3AKsM613FbA5N3HoP6tBXfr5PvrXFfKw3a4CHwHfATFAGPBuDttolJHPWQOYAfxrpGxshtcz9H+Dl4HLwAPg94zx6suNzBDzLeDnDLFmrPeqsXr0895AO3hJ1v98PdNyqf9brNNv4yvAMHP/7xX3SV0TKDli9VNvIYRDHt73M9pRYifAFximf53ZR8AawBsI1P/+I/AN0AQIR9txAiCEeBbtn3Uj0BD4APgQmJBDLH5ALaAL8BIwAm1nlRMXYDvQVR/bBmCjEKJeps84Aq0ppD7amVI02g62n75MA7QmtP8YqWMdUEZfx8PP54K2vVbmMo6+aDvrWfp6njT2YfKw3f4PbafbFPgcmCeEaGVsncBaoJv+9xb6ukOzKWtMDWAQ0Ad4Hu3v/WmGmN9AS0g/AY3QmiP/1S9urv/5ur7eh68NCCH6AF8Bi4FngCXAN0KIXpmKTkdLtt76z7VcCFEtD59FyczcWUhNppvQdmhRQCJwCJgPPJepTAD6o2+gLtrRVcsMy6sCaWQ9E5ib4fUz+nmTMszzIcMRLfArsDtT3TOAsGxiqaN/f5sMy6tnjiWX2+Ew8JH+99r69XbLpqxB3Bnm+6E/E9C/3gisyPB6GHAfcMhNHPrXV4F3cqo/l9vtKrA6U5mLGesyEkszfT01Mq03N2cCiUCZDPOmApcyvA5Du+6UXd0S6P+Yeg4Ay438Dfbn8D20QTszVWcDBZjUmUAJIqXcAHgCvdCOSlsDh4UQU7J5Sz1Ah3Zk/3AdoWhH9ZmdyvD7Lf3P00bmVdT/rI/2j53RfqCyEOIJI+uvr4/laIZYrmUTSzohhLMQYp4Q4qwQ4p6+x0kz4OHRYRP9evfktJ5cWAm8JIRw0r8eCmyQUibmMo7cyu12O5WpTDiPtr2pXZOG10jS6xJCVAQqA7sKWEd2n9sr07z0zy2lTAXuUHifu1RQSaCEkVImSin9pZSzpJSt0ZpsZuh7oRRESsZqcpiXm+9UTr1g8tpDZj4wAJiGdhG8MVoiKejnzWwbkAr46nd8XXjUFFRUcWTcNilGluX1/1kHiEzzbI2UM0Vd+ZX5+2DOWEoktfFKvrNop83GrhOcR/sOPPtwhhCiCtrZREGdA9pkmtcWrVnDWJfQh7G0yBBLtVzE0hb4RUq5QUp5Cq1p4ukMy0/q19sxm/cn639a51SJlDIJra1+KFr7+E205qzcxvGwrhzrIe/brSDuAB5CiIyJoHFeViC1Lp43gM45FEsh/5/7bF7iUfJOJYESQghRXgixWwgxTAjRSAjxlBBiAPAesEtKGZP5PVLKC2i9e74VQrQUQjRGu7gXT96PyDNbAHQQQswQQtQRQgwFJgPzjBXWx7ID+E4I0Uofix+P70YYDPQRQjQVQjREOzpPT3hSymDgN+AHIUQ//XZpJ4QYri9yDe2z9hBCuOsv+GZnJfACMBatTV6X2zj0rgLthBCVc7g5LE/brYAC0O5RmCKEeFoI8SrQPx/r+RSYKIT4P33MjYUQkzMsvwp0FkJU0t+vYMx/geFCiDeFELWFEG+hJdzC+NxKBioJlByxaBci/wP8DZxB6xa5Cu3INTuj0I5aA9C6iv6KdlNRYkGCkVKeQGse6Yf+hjX9lNMdwqOAEGA3sEUf+9XHVDVJH+8+tOsgh/W/ZzRCv64v0M44/NB6+yClvAF8jLYju/WY+PahHfV6YdgUlNs4pqNdeL+MdhSeRT63W75IKc+hdf0dg9bW3hXtO5PX9SwF3kTrAfQvWjJvkKHIZLQzsVDgn2zW8TvwFlqvp7No3+PxUsoteY1HyRt1x7BiQH+EGg4M1l9oVhSlBFN3DJdyQohOgCtaT5+KaEfEkWhHc4qilHAmaw4SQkwQQgQKIZKEEH45lBsphDguhIgRQoTpu9WpZGQ+tsAnaElgC9r1gPZSyjizRqUoSpEwWXOQEKIvWpezFwBHKeWobMqNQ2s3PAK4o7VDr5NSfmaSQBRFUZRcM9kRuJRyI4AQohnamDLZlVua4eUNIcSvZN99T1EURSlEltAM0x6tJ4tRQogxaL0XcHR0fLZq1apFFVe2dDodVlaqYxWobQEQGhqKlJJq1dQQNlA03wmd1JGkS8LR2rFQ6ykoS/n/CA4OjpRSuhtbZtYkIIQYjXZr/WvZlZFSLgOWATRr1kwGBgZmV7TIBAQE4OPjY+4wLILaFuDj40N0dDQnT540dygWobC/E8lpyXT/tTtHbxzln//8Q3mn8o9/k5lYyv+HEOJadsvMlgSEEC8Bc9GGPo58XHlFURQpJW9sfYPdIbvx8/Wz6ARQXJglCQghugHfAz2klKcfV15RFAVgzr45+J30Y3r76YxsPNLc4ZQIJksC+m6eNmhjhFjrx7RP1Y/0l7FcJ7S7UvtIKY9mXZOiKEpWe6/t5aM9HzGs0TBm+MwwdzglhimvWHyENs7LB2hjrScAHwkhqgkhYjM8+GEa2i37f+rnxwohtpswDkVRSqC21drybY9v+aHXDxiOeacUhCm7iM5AewCFMS4ZyqnuoIqi5NqlqEvYWtlSvWx13mj2hrnDKXEsoYuooiiKUZHxkXT/tTsONg4EjQ3CSpi/u2VJo5KAoigWKTE1kZfWvETo/VB2j9ytEkAhUUlAURSLo5M6XvnjFQ6EHuC3/r/Rumprc4dUYqnUqiiKxfn66Nes+XcNn3X+jAENBpg7nBJNnQkoimJxRjUehbWVNeOajTN3KCWeOhNQFMViHA8/TlxyHK72roxvPl51BS0CKgkoimIRzt45S+dfOjN221hzh1KqqCSgKIrZ3Yy9yYu/voijrSOfdvrU3OGUKuqagKIoZhWfEk/v1b25E3+HvaP2Uq2MGpK7KKkkoCiKWb29/W0CwwP5/eXfedbzWXOHU+qoJKAoillNaTeFDtU70Ltub3OHUiqpJKAoilkcCTtCi8otqFmuJjXL1TR3OKWWujCsKEqR2xa8jdbLW7PkyBJzh1LqqSSgKEqR+ifiHwatH0TjSo15rWm2T5ZViohKAoqiFJmwmDB6ru6Jm6MbWwZvwcXO5fFvUgqVuiagKEqR0Ekdfdf25UHSAw6MPoCnq6e5Q1JQSUBRlCJiJaz4vMvnpOhSaOjR0NzhKHoqCSiKUqiklByPOE4zz2Z0fEo9WNDSqGsCiqIUqgWHFtD8++YEXA0wdyiKESoJKIpSaDac3cC7/u8ysMFA2ldvb+5wFCNUElAUpVAcCTvCsE3DaFWlFX6+furxkBbKpH8VIcQEIUSgECJJCOH3mLL/J4S4KYSIEUIsF0LYmzIWRVHMJyohit5reuPp6skfL/+Bo62juUNSsmHq1BwOfAIsz6mQEOIF4AOgM1AdqAnMNHEsiqKYiZujG7M7zubPIX/i7uxu7nCUHJi0d5CUciOAEKIZUCWHoiOBH6WUZ/TlZwO/oiWGbF24cAEfHx+DeQMHDmT8+PHEx8fz4osvZnnPqFGjGDVqFJGRkfTv3z/L8nHjxjFo0CBCQ0MZPnx4luWTJ0+mV69eXLhwgTfeeAOA6OhoypYtC8BHH31Ely5dOHnyJBMnTszy/jlz5tC6dWsOHjzIlClTsixfvHgxjRs35n//+x+ffPJJluXfffcddevWZcuWLSxYsCDL8hUrVlC1alXWrl3L0qVLsyxfv349FSpUwM/PDz8/vyzL//zzT5ycnPjmm2/47bffsiwPCAgAYP78+WzdutVgmaOjI++//z4As2fPZteuXQbLy5cvz4YNGwD48MMPOXTokMHyKlWqsHLlSgAmTpzIyZMnDZbXqVOHZcuWATBmzBiCg4MNljdu3JjFixcDMGzYMMLCwgyWt2rVirlz5wLQr18/7t69a7C8c+fOTJs2DYDu3buTkJBgsLxnz5688847AFm+d/Dou6fT6bh06VKWMoXx3cvIEr97OqHjduptKllXKvTv3vbt24HS/d3L734vI3N1EW0A/JHhdRDgIYQoL6U02FpCiDHAGABbW1uio6MNVhQcHExAQACJiYlZlgGcP3+egIAA7t+/b3T5mTNnCAgI4Pbt20aXnz59GldXV65fv56+PC0tLf33oKAgbGxsuHTpktH3nzhxguTkZP7991+jywMDA4mOjiYoKMjo8iNHjhAREcHp06eNLj906BCXL1/mzJkzRpcfOHCAMmXKcP78eaPL9+7di4ODA8HBwUaXP/xHvHz5cpblCQkJxMbGEhAQQEhISJblOp0u/f0Zt99Dtra26cvDwsKyLA8PD09fHh4enmV5WFhY+vJbt25lWX79+vX05Xfu3CEmJsZgeUhISPryqKgokpKSDJZfvnw5fbmxbfPwuxcdHY2UMkuZwvjuZWRp3z2JJLRpKPc972Ptb13o372Hyy35uxcbG2vS755OZ4NO50xg4B1++eUoMTGp3LhRA53OAZ3OHp3OASkdWLWqLEeOXOb+/WTOnRsO/E12hJQy24X5JYT4BKgipRyVzfLLwJtSyh3617ZAMvCUlPJqdutt1qyZDAwMNHm8eRUQEGA0O5dGaltoR2rR0dFZjiZLm0/2fsK0PdMYVX0UP436ydzhWISM/x+pqRAdDXfvQlTUo+nuXbh3Dx48gJgY7Wd2vycn5zcScVxK2czYEnOdCcQCT2R4/fD3B2aIRVGUAlp1ehXT9kxjhPcIRpQZYe5wioSU2o755s2s061b2s/Ll5uSkqLt6O/fL3idNjbwxBPg7AxOTtrk6KhND3/P/NPREaZOzWGdBQ8rX84A3sDDhkBv4FbmpiBFUSzfPxH/8Mofr+BTw4fve33PwX0HzR2SSSQnQ1gYXL/+aLp2zfB1fPzj1vLoWFcIKFcO3Ny0qXz5R7+XK6ft3F1ds/7M+Lu9vbae3MWfzKpVqxg5cmTRJQEhhI1+ndaAtRDCAUiVUqZmKvoL4CeE+BWtR9FHgJ8pY1EUpWg8U/EZPmz7IW8/9zZ21nbmDidPUlPh6lW4eBGCg7Xp4e/Xr2tH+zlxdoZKlQwnD49Hv4eGHuf555/FzQ3KlgWrIrpVIjY2lm7dunHgwAG6d++eY1lTnwl8BHyc4fUwYKYQYjlwFvCSUl6XUu4QQswD9gCOwIZM71MUxcJFxkeSpkvDw8WDGT4zzB1OjqTUjupPnzaczp/Pvp3dygqqVIFq1R5N1asbvi5TJud6AwIeUKuW6T9PTqKiovDx8eHixYu4uroSHh6eY3lTdxGdAczIZrHBwOFSyoXAQlPWryhK0UhMTcR3jS/3Eu5xatwpbKwsZyxKKSE0FI4efTQFBWkXZY2pWhXq1IHatR/9rF0bnnoK7IrXiQ3h4eG0bduWsLAwUlJSsLOz48aNGzm+x3L+coqiFAs6qWPU76M4GHqQdQPWmT0BJCbC4cNw4IC2wz9yRLswm1mFCtCwoeHUoAG4lJDn2ly6dIm2bdsSGRlJWloaACkpKUV7JqAoSsn30e6PWHtmLZ93+Zz+XjnfiFQYkpO1Hf2ePdp06BBk6maPmxu0aPFoatpUa6PP7UXV4iYoKAgfHx/u379Pxm7/CQkJhIaG5vhelQQURcm11adXM3f/XMY0HcO7rd8tsnqDg2HrVti+XTviz3SDLY0aQYcO0LKlttN/+umSu8PP7MCBA3Tr1o3Y2Fijyy9dupTj+1USUBQl155/+nk+aPMBszrOQhTiXjYlBfbu1Xb8W7dC5v1YgwbQsSP4+Gg7/woVCi0Ui7Zt2zYGDhxIfA59Va9du5bjOlQSUBTlsa5GX+VJlycp71SeuV3mFkodqala885vv8HGjdrdtA+5uUH37tCjB3TuDBUrFkoIxcrKlSsZM2ZMlnGHMouIiMhxuUoCiqLkKOJBBB38OtC6amtW91tt0nVLCfv3w8qV2o4/MvLRsvr1wdcXevaE557T7pZVNN999x0TJ04kMTHxsWUjM25UI9RmVRQlW3HJcfRa3Yu78XdNeg0gLAx++QV++smwqaduXRg0CAYO1Jp8FONiYmKwtbXF1taWBw9yHm1Hf6aQbdudetSPoihGpenSGLpxKP/c/Ic1/dfQ9MmmBVtfGvz+u9asU726Np7NpUvg6QkffACnTsG5czBzpkoAj/Puu+8SGRnJihUraNWqFQ4ODtmW1S+zzW65OhNQFMWoaXum8ceFP/ii2xf0rNMz3+u5dw+WL4evvtKGaADtJixfX3jlFXj+ebC2Nk3MpYmdnR2+vr4EBQVx4sSJbMvZaO1o2d72ppKAoihGDW04FGdbZ9567q18vf/CBVi8WGv2edh5pWZNmDABRozQBlBTCkZKydKlSw2eR2Bvb4+XlxcXL15ECPGwOUidCSiKkjtX7l3hqbJP0aBiAxpUzHu7zOXLznz7rdbL5+F9S127wttva01B6qjfdA4cOJDl/gAhBJs2baJSpUps3bqV7777Dn9//8yDeKZT1wQURUl3IuIEjZY2YuGhvA/rdfSo1sTz2mvNWbtW683z2mtw5gzs3Kn18lEJwLSWLl1KXFycwbxGjRpRvXp17O3t6devHzt37oQcntWizgQURQEg9H4oPVf1pLxTeYY2Gprr9506BR9+CH/+qb22s0tj7Fhr3n1XG4VTKRxxcXFs2rTJYJgIFxcXJkyYkKf1qCSgKAoxSTH0XN2TuJQ4Dgw/QCWXSo99z/XrMH261uYvpTYQ25tvQosWh+nbt00RRF26bdiwAetMp1ZpaWn069cvT+tRzUGKUspJKRmyYQhn75xl/YD1PFPxmRzLR0XBu+9qwy7//LPW7PP223DlCnz2Gbi5pRRR5KXbl19+aXA9QAhB3759cXJyytN61JmAopRyQgheb/o6/er3o+vTXbMtp9NpN3e9/772zFyAwYNh9mxtwDal6Fy9epV///3XYJ6zszPjxo3L87pUElCUUuz6/etUK1MN33q+OZY7cQLGj9eGcAZt0LYFC+DZZ4sgSCWL5cuXG1wLAHB1daV169Z5XpdqDlKUUmr92fXU+qIW/pf9sy1z757Wr795cy0BPPkkrFqlDfSmEoB56HQ6vvvuO4N7AxwcHBg3bly+RnZVZwKKUgodDjvM8E3DaV65Oe2qtzNaZssWGDMGbt7UunZOmgQffwxPPFHEwSoG9u3bZ3To6FdeeSVf61NJQFFKmSv3rtB7dW88XT35fdDvONgYjjsTFQX/+Y82sidAmzbw7bfwTM7Xi5Ui8s0332S5N6BJkyZUyWd/XNUcpCilSGxyLD1W9SBVl8qfQ/7E3dndYPmWLdrgbStXgqOjNuzD3r0qAViK2NhYNm/enOXegLfffjvf6zRpEhBCuAkhNgkh4oQQ14QQQ7IpZy+E+FYIcUsIESWE2CKEqGzKWBRFycrZ1pnhjYazadAm6laomz7/wQMYNQp699aaf9q2haAg7YzASh0qWox169ZluTdAp9Ph65vzhf2cmPrP+zWQDHgAQ4GlQghjg4/8B2gFNAI8gXvAlyaORVEUPSklN2JuIIRgSrspdKjRIX3ZiRPaRd6ff9aO/hctgr//htq1zRiwYpSfn5/B9QArKysGDBiAo6NjvtdpsiQghHAG+gHTpJSxUsr9wGZguJHiTwF/SSlvSSkTgbWAGkFcUQrJrL9n0XBpQ65GX02fJyUsWaI9nP3iRe1h7cePw8SJ6ujfUn311VeMGjUKJycnXFxcsLe3z9e9ARmZ8sJwHSBVShmcYV4Q0MFI2R+BJUIITyAa7axhu7GVCiHGAGMAPDw8CAgIMGHI+RMbG2sRcVgCtS0gOjqatLQ0i90O/rf8mXN+Di94vEDIPyFcFVe5f9+Wzz+vy6FD2hPafX1vMG7cZW7d0nHrVsHqU9+JRwpjW4wYMYKXX36Z/fv3c/78eeLj4wtWh5TSJBPQDriZad7rQICRsmWANYAEUoF/ALfH1fHss89KS7Bnzx5zh2Ax1LaQskOHDtLb29vcYRgVEBIgbWfZyo5+HWVSapKUUsqjR6WsUkVKkLJsWSk3bjRtneo78YilbAsgUGazXzXlSV8skLkH8RMYH8L0a8AeKA84AxvJ5kxAUZT8uRx1mT5r+/C029NsGLgBO2s7/PygXTvtGb8tW8LJk9Cnj7kjVczJlEkgGLARQmS8nOQNnDFStjHgJ6WMklImoV0UbiGEqGDCeBSlVPN09WRgg4FsG7INF5tyvP229jjHpCR44w3t4m/16uaOUjE3k10TkFLGCSE2ArOEEK+h7eh9AWODWRwDRgghAoB4YDwQLqWMNFU8ilJaJaQkkJyWTBmHMnzb81tu34YuXbT+/ra28PXX8Prr5o5SsRSm7gMwHnAEbgOrgXFSyjNCiHZCiIzPQHsHSAQuAneAFwF1UqooBaSTOkb+PpK2P7UlKTWJf//Vxv3Zu1cb9+fvv1UCUAyZdNgIKWUU8JKR+fsAlwyv76L1CFIUxYSm7prKurPr+G/X/7IvwJ5+/SAmRmv/37hRSwRK0Zk4cSJt27blq6++Mnco2VK9gRWlhPj++Pd8duAzxj47lnLnJtO9u5YABgyA3buLTwK4c+cO48ePp0aNGtjb2+Ph4UHnzp3x989+tNOMAgICEEIQGVl0rct+fn64uLhkmT9r1izmzp1bZHHkhxpATlFKgF1XdjFu2zi6Pd0dt8Nf89qn2pDC770Hc+cWr5u/+vXrR3x8PD/++CO1atXi9u3b/P3339x9+CSbIpScnIydnV2+3//EE0/g6upqwogKQXZ9Ry1xUvcJWB61LSzjPoGw+2FyyG8j5aDByRKktLKSculS88RSkO/EvXv3JCD9/f2zLbNixQrZrFkz6eLiIt3d3WX//v1lWFiYlFLKkJAQiXb/Ufo0cuRIKaX2d3rzzTcN1jVy5EjZo0eP9NcdOnSQY8eOlZMnT5YVKlSQzZo1k1JKuWDBAtmwYUPp5OQkPT095auvvirv3buX/nkz1/nxxx9LKaX09vY2qLN69epy9uzZcsyYMdLV1VVWrlxZzps3zyCmCxcuyPbt20t7e3tZp04duW3bNuns7Cx/+umnfG1TKYvuPgFFUYpYVEIUabo0ytlUJtrPj7WrbXFxga1bYexYc0eXdy4uLri4uLB582YSExONlklOTmbmzJkEBQWxdetWIiMjGTx4MABVq1Zlw4YNAJw5c4aIiAiWLFmSpxhWrlyJlJJ9+/bxyy+/ANoYPYsXL+bMmTOsWrWKo0eP8tZbbwHQunVrFi9ejJOTExEREURERPDOO+9ku/5FixbRsGFDTpw4wfvvv897773HoUOHAG0wuD59+mBjY8Phw4fx8/Nj5syZBg+QMTXVHKQoxVRcchxdV3SlpmNTbi77nv37oXx52LEDmjUzd3T5Y2Njg5+fH6+//jrLli2jSZMmtGnThgEDBvDcc88BMHr06PTyNWvWZOnSpdSvX5+wsDCqVKmCm5sbABUrVqRChbzfevTUU0+xYMECg3kTJ05M/71GjRrMmzcPX19ffv75Z+zs7ChTpgxCCCpVqvTY9T///PNMmDABgLfeeosvvviCXbt20apVK/z9/blw4QI7d+6kcmVtYOVFixbRpk2bPH+O3FJnAopSDKXp0hi8YTD/XArnxNz57N8PVarAvn3FNwE81K9fP8LDw9myZQvdu3fn4MGDtGzZkjlz5gBw4sQJfH19qV69Oq6urjTTf+Dr16+bpP5njTw3c/fu3XTt2pUqVarg6upK3759SU5O5ubNm3lef6NGjQxee3p6cvv2bQDOnz+Pp6dnegIAaN68OVaFeFFHJQFFKYYm75zMlqNBVFhzjivnylC7NuzfD/Xrmzsy03BwcKBr165Mnz6dgwcP8uqrrzJjxgzu37/PCy+8gJOTEytWrODYsWPs2LED0JqJcmJlZZXl4ewpKSlZyjk7Oxu8vnbtGj169KB+/fqsW7eO48ePs3z58lzVaYytra3BayEEOp0uz+sxFZUEFKWY+fro1yz5cysuK09yJ7QsjRtrZwAleQgILy8vUlNTOXnyJJGRkcyZM4f27dtTr1699KPohx725klLSzOY7+7uTkREhMG8oKCgx9YdGBhIcnIyixYtolWrVtSpU4fw8PAsdWauLz/q1atHeHi4wfoDAwMLNUmoJKAoxYx7Yhucfj1GbGQ52rSBPXvAw8PcUZnG3bt36dSpEytXruTUqVOEhISwbt065s2bR+fOnfHy8sLe3p6vvvqKK1eusG3bNqZNm2awjurVqyOEYNu2bdy5c4fYWG2wgk6dOrF9+3Y2b97MhQsXmDRpEqGhoY+NqXbt2uh0OhYvXkxISAirV69m8eLFBmVq1G0H6yoAACAASURBVKhBYmIi/v7+REZGGn0QfG507dqVunXrMnLkSIKCgjh8+DCTJk3CxsYGIUS+1vk4KgkoSjERlRDFhQsw8eXGxEeVo3177SJw2bLmjsx0XFxcaNmyJUuWLKFDhw40aNCAKVOmMGTIENauXYu7uzs///wzv//+O15eXsycOZOFCxcarKNy5crMnDmTqVOn4uHhkX4RdvTo0elTmzZtcHV1pU8uhlBt1KgRS5YsYeHChXh5efHDDz8wf/58gzKtW7dm7NixDB48GHd3d+bNm5evz29lZcWmTZtISkqiRYsWjBw5kqlTpyKEwMHBIV/rfKzs+o5a4qTuE7A8alsUzX0C16KvSff32knX8g8kSOnjI2VsbKFWmW/qO/GIKbbFyZMnJSADAwPzvQ5yuE9AdRFVFAsXkxRD5wVvEfnNOmSsC506wZYt4ORk7siUwrBp0yacnZ2pXbs2V69eZdKkSXh7e9O0adNCqU8lAUWxYClpKby4ZBKXFi6DOA+6dIE//lAJoCR78OAB77//PqGhoZQrVw4fHx8WLVpUaNcEVBJQFAs2YvkMDnwyE+I86NpVSwCOjuaOSilMI0aMYMSIEUVWn0oCimKhQkPhfzM+gAeutG8Pv/+uEoBieqp3kKJYoIvXYujSBSLDXWnRQhsLSDUBKYVBJQFFsTA7Th2j3nNhBAeDt7fWDdTSRyNWii+VBBTFggRdC6FXDxt0t7yoXTeVnTuhXDlzR6WUZCoJKIqFCL8XReuut0gNa0LVGsns2WVDxYrmjkop6VQSUBQLkJCcjPfzp4m/2BI392QCdtmRYSBJRSk0KgkoiplJCRPfsiEysAOOLsns9rejZk1zR6WUFiZNAkIINyHEJiFEnBDimhBiSA5lmwoh9gohYoUQt4QQ/zFlLIpSXEyZlsyyZVbY28OObXZ4e5s7IqU0MfV9Al8DyYAH0BjYJoQIklKeyVhICFEB2AH8H7AesAOqmDgWRbF4wz88wsrPnsPKSrJ2raB9e3NHpJQ2JjsTEEI4A/2AaVLKWCnlfmAzMNxI8UnAX1LKX6WUSVLKB1LKc6aKRVGKg+lfnmXl580B+ObbNHx9zRyQUiqZsjmoDpAqpQzOMC8IaGCkbEsgSghxUAhxWwixRQhRzYSxKIpF+3H9dWb/Xy2QVkyflcAbr6ub9xXzMOU3zwWIyTTvPmDsNpcqQFOgK3AamAesBrI8TVkIMQYYA+Dh4UFAQIDpIs6n2NhYi4jDEqhtAdHR0aSlpeV6O5w4K3nn/5pDmh0v9jmPT9ublKRNqL4TjxSHbWHKJBALPJFp3hPAAyNlE4BNUspjAEKImUCkEKKMlPJ+xoJSymXAMoBmzZpJHx8fE4acPwEBAVhCHJZAbQsoW7Ys0dHRudoO16/D4CE6ZLIVz/veZcv6elhZ1Sv8IIuQ+k48Uhy2hSmbg4IBGyFE7QzzvIEzRsqeAjI+8VkaKaMoJUrUPR3du+u4GWFFhw6weW15rFQnbcXMTPYVlFLGARuBWUIIZyFEG8AXWGGk+E9AHyFEYyGELTAN2J/5LEBRSorkZGjS8Qpnz1pRt56OTZvA3t7cUSmK6W8WGw84ArfR2vjHSSnPCCHaCSFiHxaSUu4GpgDb9GVrAdneU6AoxZmU0P6li1wPqoVTufvs2C7UeECKxTBplwQpZRTwkpH5+9AuHGectxRYasr6FcUSDZ1wmSPba2Ntn8Duv5ypUaNwnhClKPmhWiQVpRDNWBjG6m+eBpHGmrWS55qrrqCKZVFJQFEKyY4d8Ml72ihwny2Kob+veiqMYnlUElCUQnAkMIkBAyRpaYIPP4T3/6MuAiiWSSUBRTGxkKtpdOgaS2ysYMgQySefmDsiRcmeSgKKYkLR0dDM5xZJ0eWp3fQGy5cLdS+AYtHU11NRTCQ5GVp0DSXqmidu1W5y5H+V1b0AisVTSUBRTEBK6D7oOhcDq2Jf5h7HAiqqewGUYkH1V1MUE7h1awynTlXDyi6B/+1wpOZT6vhKKR5UElCUAoq41ZVbt8ZjZQWb1jnQtqW6GUwpPtThiqIUwJa/YgkOfheAJUugd2+VAJTiRSUBRcmnoNMp9O0L6OwoU+1HJkwwd0SKkncqCShKPty8KWnbJZrUeBdcKu+ketmvzR2SouSLSgKKkkfx8dC8UwSxt915sm4YjZ9agBA6gzIbNmzA29ub8ePH8+uvvxIcHIxOp8tmjYpiPurCsKLkQVoaDB0KYec8ca54hxMBlXn55aQs5erVq8fp06c5deoUK1asQEqJTqejQYMG+Pj40KpVK5o1a0bVqlURQl1HUMxHJQFFyYNJk9L4/XdrypaFA3sqUKmS8R14gwYN6NSpE7t27SI2Nv1RGgQGBnLixAlcXFxISUnB1taWRo0a0bFjR1q2bEn79u1xcXExuk5FKQyqOUhRcmna3Dt88YU1Nrbak8G8vHI+gv/kk09wcso6cqhOpyMmJoaEhARiYmLYv38/c+bMoXfv3syfP7+wwlcUo1QSUJRcWPFbDJ9MLQ/A3CW3yc2zw1u2bEm9erl7iLxOp6NatWq8++67BYhSUfJOJQFFeYyDh5MZNdwWpBWvTrrGO+Mq5fq9n376aa6ad5ydndm5cyfOzs4FCVVR8kwlAUXJwdWrks7d49ElO9Le9wrfz6+ep/e/8MILVKqUc9Kwt7enV69ePP300wUJVVHyRSUBRclGVBS8+CIkRpelZtMQ/H+rSV478gghmD17do5nA0lJSWzevJnu3bsTExNTwKgVJW9UElAUIxISoFdvyblzggYNJIH/q4GdXf7W1b9//8c2CcXFxREQEECDBg04d+5c/ipSlHwwaRIQQrgJITYJIeKEENeEEEMeU95OCHFOCBFmyjgUpSDS0qDrS3c4eEBQyTOVHTsE5crlvy+/jY0NH3/8cZb2fkdHR4PXSUlJ3Lhxg+bNm7N+/fp816coeWHqM4GvgWTAAxgKLBVCNMih/LvAHRPHoCj5JiUMe+0eB3a6Y+V4n41b4qlSpeDrHTVqFLa2tumvnZycGDhwYJZEIKUkLi6OESNG8H//93+kpaUVvHJFyYHJkoAQwhnoB0yTUsZKKfcDm4Hh2ZR/ChgGzDVVDIpSUFNmxLLGrxzYJLJ6fTytmj5hkvU6ODjw3nvv4eDggJOTE99//z1+fn78/PPPRu8lSEhIYNmyZbRr147IyEiTxKAoxpjyTKAOkCqlDM4wLwjI7kzgS2AKkGDCGBQl3777IZnPZrmA0PHZN6EMfPFJk67/zTffxMrKilGjRjFkiNZSOmDAAI4dO0aVKlWwz/Qsyvj4eI4fP46XlxfHjx83aSyK8pCQUppmRUK0A9ZJKStlmPc6MFRK6ZOpbB9gjJSyuxDCB1gppTR60i2EGAOMAfDw8Hh2zZo1Jom3IGJjY9Wt/XolZVscPuzG1KnPoNNZ0ePV7bwzzPHxb9KbOHEiaWlpfPnll48tGxERQcWKFbG2tjaYHxcXx4wZMzh9+jRJSVnHIrK3t+ftt9/mxRdfzHVc5lJSvhOmYCnbomPHjsellM2MLpRSmmQCmgDxmeZNBrZkmucMXARq61/7AGG5qePZZ5+VlmDPnj3mDsFilIRtceSIlE5OOglSfvCBLs/v79Chg/T29i5wHGlpaXLmzJnS0dFRAlkmJycn+corr8ikpKQC11WYSsJ3wlQsZVsAgTKb/aopm4OCARshRO0M87yBM5nK1QZqAPuEEDeBjcCTQoibQogaJoxHUR7r33+h0/OJxMcLhgxLYc4c843oaWVlxfTp09m4cSOurq5YWRn+e8bHx7NmzRqaNWvGjRs3zBSlUtKYLAlIKePQduizhBDOQog2gC+wIlPRf4GqQGP99BpwS/97qKniUZTHuXwZOnROJO6+AxWbHuGHH0SebwYrDN26dSMoKIinn34aBwcHg2UJCQmcO3eOZ555hr1795opQqUkMXUX0fGAI3AbWA2Mk1KeEUK0E0LEAkgpU6WUNx9OQBSg079W/eGUIhEeDh06JRF12wGXukf5d7cXjvaWM7L6U089RVBQED179szSeyg1NZXo6Gi6devGggULHjazKkq+mDQJSCmjpJQvSSmdpZTVpJSr9PP3SSmNXh2RUgbIbC4KK8b5+PgwQT3QNt/u3oWOnVO4cd0e26onCdxVBfcyruYOKwtHR0d+++035s6dm+V+AtDOCqZPn07fvn2Ji4szQ4RKSVBqho24c+cO48ePp0aNGtjb2+Ph4UHnzp3x9/fP1fsDAgIQQhRpn20/Pz+jPQs2btzI3Lnq9or8iImBbt0g+Lwt9k9exH+HDXUre5o7rGwJIXj77bfx9/enXLly2NgYnq3Ex8ezY8cOvL29uXz5spmiVIqzUpME+vXrx9GjR/nxxx8JDg5m69atdO/enbt37xZ5LMnJyQV6v5ubG66ulnfkaukSEqB3b0lgINSsCReP1qSD1zPmDitX2rRpw5kzZ3jmmWeynBUkJiYSEhJC48aN2bZtm5kiVIqt7LoNWeKU3y6i9+7dk4D09/fPtsyKFStks2bNpIuLi3R3d5f9+/eXYWFhUkopQ0JCsnTXGzlypJRS6x745ptvGqxr5MiRskePHumvO3ToIMeOHSsnT54sK1SoIJs1ayallHLBggWyYcOG0snJSXp6espXX31V3rt3T0qpdS3LXOfHH39stM7q1avL2bNnyzFjxkhXV1dZuXJlOW/ePIOYLly4INu3by/t7e1lnTp15LZt26Szs7P86aef8rVNH7KULnCPk5wsZc+eWjdQZ7doeelS3ruCZsdUXURzIykpSb7++uvSycnJaDdSR0dH+dFHH8m0tLQiiceY4vKdKAqWsi0ooi6iFsvFxQUXFxc2b95MYmKi0TLJycnMnDmToKAgtm7dSmRkJIMHDwagatWqbNiwAYAzZ86wYcMGlixZkqcYVq5ciZSSffv28csvvwBal8DFixdz5swZVq1axdGjR3nrrbcAaN26NYsXL8bJyYmIiAgiIiJ45513sl3/okWLaNiwISdOnOD999/nvffe49ChQ4D21Ko+ffpgY2PD4cOH8fPzY+bMmUZvSiqJUlLg5Zdh61YBjnfpP3cZTz9tAd2A8sHOzo5ly5axdOnSbIebWLhwIV27diU6OtoMESrFTnbZwRKngtwstn79elmuXDlpb28vW7ZsKSdPniwPHz6cbflz585JQIaGhkopHx2Z37lzxyC75/ZMoGHDho+Ncfv27dLOzi79KO6nn36Szs7OWcoZOxN4+eWXDcrUqlVLzp49W0op5Y4dO6S1tXX6mY2UUh44cEACJf5MIDlZyv79pQQpcYiSHee8K9N0pj1KLsozgYz++ecf6eHhIe3s7LKcEdjZ2UlPT095+vTpIo/L0r8TRclStgWl/UwAtGsC4eHhbNmyhe7du3Pw4EFatmzJnDlzADhx4gS+vr5Ur14dV1dXmjXT7rC+fv26Sep/9tlns8zbvXs3Xbt2pUqVKri6utK3b1+Sk5O5efNmntffqFEjg9eenp7cvn0bgPPnz+Pp6UnlypXTlzdv3jzLzUglTWoqDBsG69cDDtF4Tfo/tr4zAytRMj5348aNOXv2LC1atMhyVpCcnEx4eDjPPfccq1evNlOESnFQMv4bcsnBwYGuXbsyffp0Dh48yKuvvsqMGTO4f/8+L7zwAk5OTqxYsYJjx46xY8cO4PEXca2srLL0005JSclSLvNY8teuXaNHjx7Ur1+fdevWcfz4cZYvX56rOo3JOEwxaL1KdDpdntdTUqSmwvDh8Ntv4OSSwlNvjWX3h5/jZJu1CaU4c3NzIyAggAkTJhjtRhofH89rr73GBx98YIbolOKgVCWBzLy8vEhNTeXkyZNERkYyZ84c2rdvT7169dKPoh+y0z9WKvP47u7u7kRERBjMCwoKemzdgYGBJCcns2jRIlq1akWdOnUIDw/PUqcpxpOvV68e4eHhBusPDAwssUkiNRVGjoQ1a8DVFXb52xL82Uo8XDzMHVqhsLa25vPPP2fVqlU4OzsjMt32LKUkNjbWTNEplq5UJIG7d+/SqVMnVq5cyalTpwgJCWHdunXMmzePzp074+Xlhb29PV999RVXrlxh27ZtTJs2zWAd1atXRwjBtm3biI6OTv+n6tSpE9u3b2fz5s1cuHCBSZMmERr6+NEvateujU6nY/HixYSEhLB69WoWL15sUKZGjRokJibi7+9PZGQk8fHx+fr8Xbt2pW7duowcOZKgoCAOHz7MpEmTsLGxybLDKO6Sk2HwYFi1Cqwd4nnri620bAk2VpZzN3Bheemllzh+/DjVqlVLH5baxsaG+vXrs2jRIjNHp1iqUpEEXFxcaNmyJUuWLKFDhw40aNCAKVOmMGTIENauXYu7uzs///wzv//+O15eXsycOZOFCxcarKNy5crMnDmTqVOn0rdv3/Q7dkePHp0+tWnTBldXV/r06fPYmBo1asSSJUtYuHAhXl5e/PDDD8yfP9+gTOvWrRk7diyDBw/G3d2defPm5evzW1lZsWnTJpKSkmjRogUjR45k6tSpCCGyjE1TnCUkQJ8+2jUAO+d40oZ0oXbj0vVAlrp163L69Gk6d+6Mg4MDTzzxBNu2bcvSXKgo6bK7YmyJkxpK2nROnjwpARkYGFig9VjKtoiJkbJjR60XkFOZOMmYJvKjXR8VSd3m6h2UE51OJ7/++usC/33zw1K+E5bAUrYFOfQOKvnnyAoAmzZtwtnZmdq1a3P16lUmTZqEt7c3TZs2NXdoBXbvHrz4Ihw+DGXdE4ge0IwhnZswq+Msc4dmNkIIxo8fb+4wlGJAJYFS4sGDB7z//vuEhoZSrlw5fHx8WLRoUbG/JnDrljYW0MmTUL069J27nMDECizvvbzYfzZFKQoqCZQSI0aMYMSIEeYOw6SCg7UEEBICdepI/vc/QdWqb5KSNgZba9UGrii5USouDCslz+HD0Lq1lgAaN03libE9CeUggEoAipIHKgkoxc6WLdCpk/ZcgG7d03B6rQen43ZluWlPKbgaNWpk6bWmlCyqOUgpVr77DsaPB50ORo+WxHcbxY6zO1ndbzVtqrUxd3jF0qhRo4iMjGTr1q1Zlh07dizL3e5KyVLizgQWLFjAmjVruH//vrlDUUwoLQ3eew/GjtUSwMcfw5NDprPm7Eo+7fQpLz/zsrlDLJHc3d2NjlZa1Ar6DA4leyUqCYSHhzNlyhTGjBlDxYoVadmyZfqwzUrxdf8+9OoF//0v2NjA99/DtOlpnLt7llebvMqHbT80d4glVubmICEEy5YtY8CAATg7O1OzZk1Wrlxp8J47d+7w8ssvU65cOcqVK0ePHj24ePFi+vLLly/j6+tLpUqVcHZ2pmnTplnOQmrUqMGMGTMYPXo0ZcuWZejQoYX7QUuxEpUEtmzZgo2NDQ8ePCA5OZkjR44wffp0c4elFMDFi9CyJWzfDuXLw//+B6++KrG2smbdgHUs7bFUdQUtYrNmzcLX15egoCAGDRrE6NGj00fbjY+PZ9KkSTg4OPD3339z6NAhnnzySbp06ZI+7ElsbCzdu3fH39+foKAg+vXrR9++fTl//rxBPQsXLqRevXoEBgamj/armF6JSgIrV640GF/H2tqa/v37mzEipSD8/aFFCzh/Hp55Bo4dA3evs3Tw60Do/VCshJXqCWQGw4cPZ9iwYdSqVYvZs2djY2PD3r17AVizZg1SSn766ScaNWpEvXr1+O6774iNjU0/2vf29mbs2LE0bNiQWrVqMXXqVJo2bcr69esN6unQoQPvvfcetWrVonbt2kX+OUuLEnNhODY2lmPHjhnMc3R0pF+/fmaKSMkvnU5r+pk6VbsW4OsLK1ZAvLhFpx97kJCSgE6WzBFQi4OMz66wsbHB3d09fdTd48ePExERkeUZ2PHx8Vy+fBmAuLg4Zs6cydatW4mIiCAlJYXExMQsz8R4+EwPpXCZNAkIIdyAH4HngUjgQynlKiPl3gVGAtX15b6RUv63IHX/9ddf2NnZGTwy0crKiueee64gq1WK2N272jDQD5+XPnUqzJoFiWnx9PLrxa3YW/w96m+ql61u3kBLsZyeXaHT6ahVq5bRB967ubkB8M4777Bjxw7mz59P7dq1cXJyYsSIEVku/qpeSUXD1GcCXwPJgAfQGNgmhAiSUp7JVE4AI4BTwNPATiFEqJRyTX4rXrNmDQ8ePDCY16tXrxL/9KyS5PBhGDQIrl+HcuXgl1+gZ0/QSR3DNg4jMDyQTYM20bxyc3OHqmSjadOmrFixggoVKlC2bFmjZfbv38+IESPSz9ITExO5fPkyderUKcpQFT2T7SGFEM5AP2CalDJWSrkf2AwMz1xWSjlPSnlCSpkqpbwA/AHku5N3amoq27dvN5jn6urKyy+rboPFgZSweDG0a6clgOeeg3/+0RIAwL2Ee1yKusTCFxbiW8/XvMGWUDExMZw8edJgunr1ap7XM3ToUNzc3PD19eXvv/8mJCSEvXv3Mnny5PQeQnXq1GHTpk2cOHGC06dPM2zYMBITE038iZTcMuWZQB0gVUoZnGFeENAhpzcJrWtHO+C7bJaPAcYAeHh4EBAQkKXMyZMns9wtmpiYiK2trdHyBRUbG1so6y2OCrot7t6147//rcuRI+UB6N8/lDFjrhASIgkJeVRuft352CYUzt+zoKKjo0lLS7PI2HLj5s2b7Nu3jyZNmhjMb9++ffpResbPdubMGSpUqJD+OnOZTz/9lFWrVvHSSy8RFxdH+fLl05+HfOPGDQYMGMB///tf2rRpg4uLC/3798fLy4ubN2+mr8NYvcVRsdhXZDfGdF4ntB35zUzzXgcCHvO+mWjJwv5xdWT3PIEJEyZIKysrCaRPnTt3zufI249nKWOEW4KCbIu1a6V0c9OeAVCunJQbNhgu/zP4TzngtwEyLjmuYEEWMkt8noA5qf+PRyxlW1BEzxOIBZ7INO8J4IGRsgAIISagXRtoJ6VMyq5cTqSUrFu3zuB5uc7OzurmEgsWFQUTJsDq1drrbt3gxx/B0/NRmaCbQQxcP5BabrVUTyBFKUSmvGoaDNgIITJ26PUGMl8UBkAIMRr4AOgspQzLb6Vnz57NckE4JSWFng8blBWLsnUrNGyoJQAnJ1i6FP780zAB3Ii5QY9VPShjX4atg7fiYudivoAVpYQz2ZmAlDJOCLERmCWEeA2td5Av0DpzWSHEUGAO0FFKeaUg9W7cuJHU1FSDefXq1cPd3b0gq1VM7MYN+M9/YMMG7XWrVlrvn1q1DMs9SHpAz9U9uZ90n/2v7KfyE5WLPlhFKUVM3X9yPOAI3AZWA+OklGeEEO2EELEZyn0ClAeOCSFi9dO3+alw9erVBv2LHRwcVFOQBUlLgy+/hPr1tQTg4gKLFsHevVkTAEBIdAgRDyJYN2Ad3pW8iz5gRSllTHqfgJQyCnjJyPx9gEuG10+Zor6IiAiuXDE8kRBC0KdPH1OsXimgo0fhzTchMFB7/dJL8MUXULVq9u9p5NGIy29fxtlO3SikKEWhWN9JtXnzZmxsDPOYm5ubGmfEzK5fh6FDtf7+gYFQpQr8/jts2pR9Alh0aBEf7/kYKaVKAIpShIp1Evj111+Ji4tLf21tbc2gQYPMGFHpFhMDU6ZA3bqwahXY28P778PZs9r4P9nZdG4Tk3dO5sydM0jU08EUpSgV2wHkYmNjOXr0qME8JycnNWqoGSQmamP8f/IJ6McRY/BgmDMHatTI+b1Hbxxl6MahtKjcghV9VmAlivVxiaIUO8U2CezcuTPLgHFCCDVgXBFKTIRNmyozdCiEh2vzWrWChQu1ZwA8ztXoq/Ra3QsPFw82D96Mo61j4QasKEoWxTYJrF69Osv9AT179lQDxhWBpCTt5q45c+DGDe36i7e39sjHl16C3D7j5Xj4caSU/DnkTyo6VyzEiBVFyU6xSAJCCCfguYdjm6gB48wjMhK+/Ra++gpu3dLm1awZy/z5Lvj6Ql7zbz+vfjz/9PO42rs+vrCiKIWiWCQBoAmw6+TJk3Tr1o3mzZtnOeJPTk6mS5cu5omuhLtwQevb//PPWhMQQOPGMG0alC0bSKdOPrlel5SSCX9OoNNTnejn1U8lAEUxs+KSBC4AKVJKu7/++osDBw6QkJBgUKBt27Y4Oqo2ZVNJSYEtW2DZMvjrr0fze/SASZOgY0et2SevAyTO2TeHbwK/oYJTBfp5qae+KYq5FYsGdCllJJB+BTg2Npa0tLT05dbW1pw6dYr33nuPo0ePGgwmp+TN5cvw4Ydaf/5+/bQEYG8Pr7+udfXcuhU6dcp9u39Gq0+v5qM9HzGs0TBm+MwweeyKouRdcTkTALgINDW2IC0tjTt37rBo0SK++eYbnJycCA4OzvbJRoqhu3dh/XptULe//34038sLxoyB4cNB/2TAfNt/fT+j/hhF++rt+aHXD4j8ZBFFUUyuOCWBE2STBB5KTU3Fzs6O3r17U6ZMmSIKq3iKjYXNm7Wbuv76Cx6OwefoCAMHajv/Vq3yd8RvzF+X/qJG2RpsGrQJext706xUUZQCK1ZJQAiR5QliGTk5OdGrVy+WLVumjjSNiIjQdvx//AG7dsHDcfesreGFF2DIEK2L5xOZnwphArM7zead1u9QxkElZ0WxJMUpCZzJKQk4OjrSuXNnfv31V3WvgF5qqjZ2j7+/1paf8QZrIaBNG+3O3gEDoGIhdNNPTE3klT9e4YM2H+BdyVslAEWxQMUpCZzNLgE4ODjQunVrNmzYgLW1dRGHZTmkhOBg2LMHdu6E3bvh/v1Hyx0coGtXbRyfnj3Bw6PwYtFJHaP/GM2af9fQp14fNSy0olioYpMEpJSR1tbWWc4E7O3tadKkCVu3bsXW1tZM0ZlHUhKcOAH798OBA3DwINy5Y1imVi1tx//CC9ClCzgX0QCd0/dMZ/W/RU8iygAAC1VJREFUq5nTaQ4DGwwsmkoVRcmzYpMEQDvij4+PT39tZ2dH/fr18ff3x8HBwYyRFb7UVO2mrX/+0Xb8x45pU1KmJzN7eEC7dtqOv2tXeMokT27Im5/++YlP933Kq01e5YO2HxR9AIqi5FqxSgKOjo7pScDW1paaNWsSEBCAc1Ed3haRqCg4d07rl//PP9oUFASZ7o8DtG6cbdpA27baz5o1TdejJz+klPx29je61uzK0h5L1QV6RbFwxSoJODs7Ex8fT0pKClWqVGH//v3FtitoUhJcuwYhIdoR/rlzj6aHwzFnVqMGNGkCTZtqU8uWBe+/b2pCCP54+Q+SUpOwtS5dzXOKUhwVqyTg4OBAcnIylSpV4uDBg5QvX97cIWUrMVHrkhkWpu3oQ0LgypVHv9+4oV3INcbZGerV057L6+2t7fAbN7a8HX5GN2NvMnHHRL7s/iXuzu7YWduZOyRFUXKhWCUBJycn2rZtyy+//EKlSpWKvP60NK2p5to1J/bt0y7C3rqljaV/44b28+HvUVE5r8vKCqpV05pvatXSmnXq19emKlXyPiKnOcWnxNN7dW/O3DnDu63fxd3Z3dwhKYqSS8UqCVhbWxOQ1xHLMklK0rpNxsQY/sz8+7172tDJkZHazj4yUpunHb23eGw9Njbw5JPg6aldnM041aypjc1TEjozpck0hm0cRmB4IJsGbeJZz2fNHZKiKHlg0iQghHADfgSeByKBD6WUq4yUE8BnwGv6WT8AH8icbgcGoqNh5UqIj8/79P/t3X9sVfUZx/H30x9jlloQ6hBkqGMaGSMY1/hjRm0WkU0kmiwEI/sR54RpFIzK9I+ZoIsmahTNUidEGZvK2FioTFEnbKkRiTLcikLETmFiTRYFaWmpUNo+++Pc0nK5/UHv6T3n3vN5JTe359zvvX367bnf537Puec5ra3BIJ/+bZoT+/tg7FgoK2tj0qQyKivh1FPh9NODwb77fsKEYH0+fZofqmW7llHbWMvjMx/nmnP7uZCwiMRS2DOBGqAdGAecB6w3s23uviOt3XzgWmA64MAGYDfwVH8v/tFHQTGzbJSUwKhRwa2ioufn9OXRo4OBvLKSo4P9KacEJRbq6rZQXV2dXSAFoPlQM2/ufZPbLriNRRctijocERkCG+DD9+BfyGwksB/4trs3pNY9C3zq7vektd0MrHT35anlG4Gb3L3fK9OWlJzrY8f+hqKiwxQXH+r3vqjoEMXFx96XlBykqOhw1l+hbGpqUoXSlL0H9zJ25FiM5H4VtL6+no6ODqqqqqIOJRb0/ugRl754/fXX33H3jBtomDOBc4CO7gSQsg24PEPbqanHerebmulFzWw+wcyB0tJSxo9fPOiAurqCW3eFzLB0dnbS1NQU7ovmkS9Hfcm+M/cx4d0JWIfRfKR54CcVsI6ODtw90dtEb0l/f/SWD30RZhIoBw6krWsGMl0/sDz1WO925WZm6ccFUrOF5QBVVVW+devW8CIeorq6usTuDmo80MiFT1/ISXYSr9W8xs6tOxPbF92qq6tpamqivr4+6lBiIcnvj3Rx6Yv+TtoM89BlK5BehLgCaBlE2wqgdaADwxKtlsMtXL3qaloOt/Dy9S9zWnnuv6YrIuEKMwk0ACVmdnavddOB9IPCpNZNH0Q7iYmOrg7m/mUu2z/bzpo5a5g2blrUIYlICEJLAu5+EFgL3G9mI83sEuAa4NkMzf8A3GFmp5vZBOBOYGVYsUj43v/8fTbt2cSTs55k5jdnRh2OiIQk7K+I3gKsAD4D9gE3u/sOM7sUeMXdy1PtlgHfAN5LLT+dWicxNW3cNBpua9AuIJECE2oScPcvCL7/n77+DYKDwd3LDvwydZMYq32/lj3Ne1h00SIlAJEClIBzWmWotny6hXlr57F6x2raO9ujDkdEhoGSgGS0e/9uZv9xNqeVn8a669apKqhIgcqrAnKSG/u/3M+sVbNo72yn7qd1fG3kMFyFXkRiQUlAjrNx10Z27d/Fqz96lSmnTok6HBEZRkoCcpw5U+dw8dcvZmLFxKhDEZFhpmMCctSjmx9lw0cbAJQARBJCSUAAWPXeKu7acBerth93+QcRKWBKAsIbH7/BDetu4LIzLuOpWf1e0kFECoySQMI17Gvg2j9dy1mjz6J2bi0jSkZEHZKI5JCSQMKtrF9JkRWx/vr1jDlpTNThiEiOKQkk3APfe4B35r/D5DGTow5FRCKgJJBAXd7F3Rvu5sMvPsTMmDRqUtQhiUhElAQS6N5/3MvDmx/mxQ9ejDoUEYmYkkDCrPj3Ch7c9CA3nX8Tt190e9ThiEjElAQSZOOujSx4aQFXTr6Smqtq+r3uqIgkg5JAQrg7j2x+hCmVU1gzZw2lxaVRhyQiMaDaQQlhZtTOraX5UDMVIyqiDkdEYkIzgQLXdqSNO/92JwcOH6CstIzxJ4+POiQRiRElgQLW2dXJvLXzWPrWUt5ufDvqcEQkhrQ7qIAt3rCYF3a+wBPff4IZk2dEHY6IxJBmAgWqZksNS99aysILFrLwwoVRhyMiMRVKEjCzMWZWa2YHzexjM7u+n7aLzWy7mbWY2W4zWxxGDNKj7UgbD735ELPPmc1jMx+LOhwRibGwdgfVAO3AOOA8YL2ZbXP3HRnaGvAT4F1gMvCamX3i7qtDiiXxykrL2HzjZkZ/dTTFRcVRhyMiMZb1TMDMRgI/BO5191Z33wT8Ffhxpvbu/rC7/8vdO9z9A2AdcEm2cQg0Hmjkvrr76OzqZGLFRMq/Uh51SCISc2HMBM4BOty9ode6bcDlAz3RglNWLwWW9dNmPjA/tdhqZh9kEWtYKoG9UQfRlyUsyeWvi3Vf5FClmakfAtomesSlL87o64EwkkA5cCBtXTNw8iCeu4RgNvK7vhq4+3Jg+VCDGw5mttXdq6KOIw7UFwH1Qw/1RY986IsBdweZWZ2ZeR+3TUArkH4KagXQMsDr3kpwbGCWux8e6h8gIiJDN+BMwN2r+3s8dUygxMzOdvf/pFZPBzIdFO5+zs+Ae4DL3L1x8OGKiEiYsj4w7O4HgbXA/WY20swuAa4Bns3U3szmAQ8CM9x9V7a/PyKx2j0VMfVFQP3QQ33RI/Z9Ye6e/YuYjQFWADOAfcA97r4q9dilwCvuXp5a3g1MBHrvAnrO3X+RdSAiInJCQkkCIiKSn1Q2QkQkwZQEREQSTEkgS2Z2tpkdMrPnoo4lCmY2wsyeSdWMajGzejP7QdRx5cqJ1M0qZEnfDvqSD+ODkkD2aoB/Rh1EhEqATwjOEB8F/Ar4s5mdGWFMudS7btY84LdmNjXakCKR9O2gL7EfH5QEsmBm1wFNwN+jjiUq7n7Q3Ze4+3/dvcvdXwJ2A9+JOrbhdqJ1swpZkreDvuTL+KAkMERmVgHcD9wRdSxxYmbjCOpJ9XmyYAHpq25WEmcCx0jYdnCcfBoflASG7tfAMzrjuYeZlQLPA793951Rx5MD2dTNKlgJ3A4yyZvxQUkgg4HqJZnZecAVwNKoYx1ug6gd1d2uiOAs8Xbg1sgCzq0h1c0qZAndDo6Rb+ODrjGcwSDqJd0OnAnsCaphUw4Um9m33P38YQ8whwbqCzhaEvwZgoOjV7n7keGOKyYaOMG6WYUswdtBumryaHzQGcNDYGZlHPsJ8C6Cf/rN7v55JEFFyMyeIrii3BXu3hp1PLlkZqsBB35O0AcvA9/t46p6BS3J20Fv+TY+aCYwBO7eBrR1L5tZK3Aojv/g4WZmZwALCGpB/S/1yQdggbs/H1lguXMLQd2szwjqZt2c0ASQ9O3gqHwbHzQTEBFJMB0YFhFJMCUBEZEEUxIQEUkwJQERkQRTEhARSTAlARGRBFMSEBFJMCUBEZEE+z9DTfR0i/Vl5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The code below displays a plot showing how as the inputs increase in magnitude, the gradient reaches zero and the backpropogation correction for the weights doesn't work?\n",
    "\n",
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.savefig(\"sigmoid_saturation_plot\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier and HE Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a method to minimize the effects of the Vanishing/Exploding Gradients problem:\n",
    "    # We need the signal to flow properly in both directions:\n",
    "        # In the forward direction when making predictions\n",
    "        # Backwards when backpropogating gradients.\n",
    "    # We don't want the signal to die out, nor do we want it to explode and saturate..\n",
    "        # In order for the signal to flow properly, we need the variance of the outputs of each layer to be equal to the variance of its inputs\n",
    "        # The gradients should have equal variance after flowing through a layer in the reverse direction.\n",
    "        # It's not possible to guarantee both unless the layer has an equal number of input and output connections.\n",
    "        \n",
    "# But there is a good compromise to allow the signal to flow properly: the connection weights must be initialized randomly.\n",
    "# The Xavier initialization strategy can speed up training considerably.\n",
    "\n",
    "# By default the tf.layers.dense() function uses Xavier initialization using the variance_scaling_initializer() function like this:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, kernel_initializer=he_init, name=\"hidden1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the insights about Vanishing/exploding gradients was that they were in part due to a poor choice of activation function.\n",
    "# Until then most people assumed that since mother nature chose to use roughly sigmoid functions in biological neurons, this was an excellent choice.\n",
    "# But it turns out that other activation functions work much better in deep neural networks :\n",
    "    # An example if the ReLU function. It doesn't saturate for positive values and is fast to compute.\n",
    "    \n",
    "# However, ReLU isn't perfect. It suffers from a problem known as dying ReLUs: during training, some neurons stop outputting anything except 0.\n",
    "# In some cases half the network's neurons are dead, especially with a high learning rate.\n",
    "# To solve this problem we could use a variant of the ReLU called a leaking ReLU.\n",
    "    # It makes it so the slope of the function when z<0 is typically set to 0.01  so that leaky ReLU never dies, it might just go to sleep.\n",
    "# There are also randomized leaky ReLUs  where the learning rate alpha is picked randomly in a given range during training, and it is fixed to an average value during testing.\n",
    "\n",
    "# It seems that large leaks where alpha is set to 0.2 performs better then alpha set to a small leak value of .01\n",
    "\n",
    "# Next, there is something called a parametric leaky ReLU where alpha(the amount of leaking) is authorized to be learned during training.\n",
    "    # Instead of being a hyperparameter, alpha(leak rate) can be modified by backpropagation like any other parameter.\n",
    "\n",
    "# In 2015, a new activation function was proposed called an Exponential Linear Unit(ELU).\n",
    "# There are a couple advantages to the ELU function:\n",
    "    # It takes on negative values when z < 0 which allows the unit to have an average output close to o. This helps alleviate the vanishing gradients problem.\n",
    "    # It has a nonzero gradient  for z < 0, which avoids the dying units issue.\n",
    "    # Third if alpha is equal to  1 then the function is smooth everywhere, including around z=0, which helps speed up Gradient Descent, since it doesn't bounce as much left and right of z = 0.\n",
    "    \n",
    "# The main disadvantage of the ELU function is that it's slower to compute then the ReLU and its variants.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEMCAYAAAACt5eaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xU1b338c+PAJJwRyRF6gFFxGtBjVcqBqp4q7fH1gcVW7QIWqnWg1gei4WCHLVeKlVUQBRFUKytVkU4VTAoLccKiodSFUWhoiAoBAghCUzW88eawBBymZBM1ly+79crr+zZs7P3d3Z2flmzZu29zTmHiIgktyahA4iISO1UrEVEUoCKtYhIClCxFhFJASrWIiIpQMVaRCQFqFinCDMrMLOHQ+dIB2aWb2bOzDo2wrZWm9mtjbCdI81ssZmVmNnqRG8vjjzOzH4UOkc6UbFuAGY23cxeDZ2jrqL/AFz0q8zMVpnZXWZ2QB3XM9jMimrZzj7/aGr7uYZQTbH8O9AZ+LYBtzPWzP5ZxVMnAY801HZqcCdQDBwZ3WajqOHY7wy80lg5MkHT0AEkuCeB24Hm+D/yJ6Pz/1+wRAnmnCsD1jfStjY2xnaAw4G/OOdWN9L2auSca5T9m0nUsm4EZtbWzKaY2QYz22ZmC80sL+b5A83sWTNba2Y7zGyFmV1Tyzp/YGaFZna9mfU1s51m9p1Ky0wws/+tJV6xc269c+7fzrk/Aa8DAyqtp4uZPWdmm6Nfc8ysRx13w34xs7vN7OPoflltZr8zsxaVljnfzN6JLvOtmb1iZi3MrADoCtxb8Q4iuvzubhAzaxP9uQsrrXNAdJ92qi2HmQ0GxgDHxLxTGRx9bq+WvZn9h5m9GD0OtpnZn83suzHPjzWzf5rZwOg7nW1m9lJNXTbR19UL+E1022PNrFt0Oq/yshXdEzHLXGZmr5tZsZn9y8zOrvQzR5rZy2a2xcyKot0tx5nZWOCnwAUxrzu/8naij48zszei+29TtEXeNub56Wb2qpndbGZfRo+zJ80sp7rXnWlUrBPMzAyYA3QBfggcD7wFLDCzztHFWgDvRZ8/BpgITDazH1Szzh8BLwJDnXOPOefeAlYBP4lZpkn08bQ6ZO0F9AF2xszLAd4ESoAzgdOAdcAbjfSHtB24FjgK+DkwEPh1TL5zgZfx/2ROBPoBC/HH9v8B1gLj8G/LO1OJc24r/u36VZWeugp43Tm3IY4cs4H7gY9jtjO78raiv5O/ALnRnP2Ag4GXosdJhW7A/wUuxf/jPB6YUM3+Ibq9j6MZOgP31bBsVSYAf8AX/HeB58ysVTTzwcAiwAFnAycAk4Cs6HaeB96Ied1/r+J1twT+GygCTo6+rtOBJyotegZwLHAWe17/zXV8LenLOaeven4B04FXq3muP/4gza40fxlwWw3rfA54POZxAfAwMBTYAgyotPytwIcxj88DSoEDa9hGAVAWzVeK/4OMAJfFLHMt8AlgMfOy8P29l0cfDwaKatnOw1XMr/HnqlnX9cCnMY//BjxXw/KrgVsrzcuPvtaO0ccX4ft7W0cfZwNbgSvrkGMs8M+ato8vdhGgW8zzhwHlwFkx6ykB2sYs8+vYbVWT55/A2JjH3aKvMa/Scg74UaVlhsU83yU67/vRxxOANUDzuhz7lbZzXfSYbV3F7+DwmPV8AWTFLDMVeGN//ibT8Ust68Q7EcgBNkbfQhaZ/1DtWKA7gJllmdmvzex/o2/ji/Ctwv+otK5L8K2ac51zf6303FPAYWZ2evTxtcBLzrnaPkSbDfTGt5ifB6Y63x0Sm/9QYFtM9i1A+4r8iWRmPzKzRWa2Prrt37P3fjkemF/PzczFF+tLo48vAgx4qQ454nEU8JWL6Vd2zn0GfAUcHbPcGufclpjHXwGd6rituojtKvsq+r1ie8cDi5zv599fRwH/65zbFjPv7/h/UrGv+1/OuUilLIl83SlFHzAmXhPga/xbvMq2Rr/fCozAv+Vbjm/p/hf7HqgfAMcBPzOz/3HR5gf4D7LM7GXgWjP7GF9wLqR2W5xznwKY2SBghZkNds5Nj8m/DP+2v7JNcawf/OtsW8X8dvjCXyUzOxX/DuO3wC1AIf511fVtfo2cczvN7Hl818fT0e8vOueKGzFH7OUvd1bxXF0bVuXR77u7V8ysWTXL7t6ec85Fe2QaqyHX0K87balYJ957+D7K8mgrqirfB15xzs2A3f3cR+CLQqzPgV/guxWmmNnQ2IKNf9v4AvAZfrTDG3UJGi1a/wXcZWbPR4vVe8AVwDfOucp54vUxcL6ZWaW8J0Sfq04f4Evn3PiKGWbWtdIy7wM/wL/2qpThu21q8wzwlpkdDZyL//ygLjni2c6HwMFm1q2idW1mh+H7rf8VR8a6qBiFEttP33s/1vM+MMjMmlfTuo73dV9rZq1jWten4wvxh/uRKSPpv1bDaWNmvSt9dcMXzL8BfzGz88zsUDM7zcx+a2YVre2VwA/M7PtmdiS+b/rQqjYSLfj98AVlcqUPpl7H9yWPAaY758qrWEVtZuFbNMOjj2fi3xn8xczOjObva2b3294jQppU8fqPjT73KL5v9iEz62VmPc3sFvw/gXtryLIS6GJmV5nZYWZ2Q/RnYk0Afmxmd5rZ0WZ2jJndEvPh52rgDPMjWqodUeGc+zu+b3YW8A17d63Ek2M10NXMTjA/yqSqsepv4LscZppZnvmRGjPx/xAX1LAf6sw5twP4H+BX0X1yOvv3TuARoBXwvJmdZGaHm9kVZlZR+FcDx0Z/px2rab3PxHczPW1+VEhfYDLw54p3dVI7FeuGcwa+FRL7dV+0JXk+/o9xKr4l+TzQkz39g3cC/8D3nb6FH3kws7oNOedW4T+gOY+Ygh3d1pNAM/aMl66TaOvpYeC2aEuoGOiLb63/EfgI3z/eHtgc86PZVbz+gug6P4uuowfw1+hrHQj82Dk3t4Ysr+CL+YP4Inc28JtKy7yG72s+L7rNhfh/ZhX/qH4DHIIfLVPbmOeZ+BERz8X2ncaTA/gT8Bq+yG9k32Je8fu5OPr8m9Gv9cAlld5xNJRro9/fxRfH0XVdgXPuS/zvrjk+7/v4d3e7ootMxbeOl+BfV58q1lEMnAO0wf/u/wIsjskncbDEHCMSipk9iv+E/exaFxaRlKE+6zRh/gSDo/Fjqy8PHEdEGpiKdfr4C/6Eg2nOuTmhw4hIw1I3iIhICtAHjCIiKSBh3SAdO3Z03bp1S9Tq47J9+3ZatmwZNEOy0L7wPv74YyKRCEcffXTtC2cAHRd7VLUvvvoK1q2DZs3g6KOhaSN0HC9duvQb59xBlecnbNPdunVjyZIliVp9XAoKCsjPzw+aIVloX3j5+fkUFhYGPzaThY6LPSrvi7ffhvx8MIN586B//8bJYWZrqpqvbhARkUo2b4arroLycvjVrxqvUNdExVpEJIZzcN118MUXcPLJMG5c6ESeirWISIzHH4c//Qlat4Znn/X91clAxVpEJOrDD+Hm6O0OHn0UDjssbJ5YdSrWZtbD/N2Tn0lUIBGREMrKmnDFFbBjB1x9te+zTiZ1bVlPwl8URkQkrUyZchgffACHHw6TJoVOs6+4i7WZDcRfX7m+d+UQEUkqc+bAn/70XZo2hVmzfH91somrWJtZG/xNR/8zsXFERBrXunUweLCfnjABTjopaJxqxXtSzHj8BYLW7n2t+72Z2VD8DV3Jzc2loKCg3gHro6ioKHiGZKF94RUWFhKJRLQvojL9uCgvh9tu+x7ffNOB3r03kpe3gmTdHbUW6+gdIc7C3zizRs65KcAUgLy8PBf6zCidnbWH9oXXrl07CgsLtS+iMv24uPdeWLoUOnaE0aM/oX///MCJqhdPyzoff8v6f0db1a2ALDM72jl3QuKiiYgkzrvvwu23++np06Fly/rcwD3x4umzngJ0x99sszfwGDAHf5seEZGUs20bXHEF7NoFN90EF1wQOlHtam1ZR++fVlzx2MyKgBLnXG33sxMRSUrDh8OqVdCrF9xzT+g08anzVfecc2MTkENEpFHMnAlPPw3Z2f508hYtQieKj043F5GM8dlncMMNfnriRDjqqLB56kLFWkQyws6dvp962za47DIYMiR0orpRsRaRjDBmDPzjH3DIITB1qr+pQCpRsRaRtLdgAdx9NzRp4vus27cPnajuVKxFJK198w0MGuRvKnDHHXDGGaET7R8VaxFJW87Btdf663/06QOjR4dOtP9UrEUkbT3yCLzyCrRr57s/GuPu5ImiYi0iaWn5chgxwk9PnQpdu4bNU18q1iKSdoqLYeBAKC31Q/R+9KPQiepPxVpE0s6IEfCvf8GRR8KDD4ZO0zBUrEUkrbz4Ijz2GDRv7k8nb9kydKKGoWItImnjiy/gZz/z07/7HfTuHTZPQ1KxFpG0EIn4u5Jv3gznn+8vfZpOVKxFJC3cdRcsXAi5ufDkk6l3OnltVKxFJOX9/e8wdqyfnjEDOnUKGichVKxFJKUVFsKVV/pukJEj4eyzQydKDBVrEUlZzsH118OaNZCXB3feGTpR4qhYi0jKmj4dZs/2w/NmzfLD9dKVirWIpKSPP4Zf/MJPP/II9OgRNk+iqViLSMopLfV3fdm+3fdXX3116ESJp2ItIinn9tvh/ffh0EPh0UfTb5heVVSsRSSlzJsHDzwAWVm+n7pNm9CJGoeKtYikjK+/hp/+1E+PHw+nnho2T2NSsRaRlFBe7gv1hg3Qrx/cdlvoRI1LxVpEUsKDD8J//zcceKA/SzErK3SixqViLSJJ7733YNQoPz1tGnTpEjZPCCrWIpLUior8ML2dO+HGG+Hii0MnCkPFWkSS2k03wcqVcOyxcO+9odOEo2ItIklr9mx/udMWLeC55yA7O3SicFSsRSQprV4NQ4f66d//Ho45Jmic4FSsRSTp7NrlTyPfuhUuuQSGDQudKDwVaxFJOr/9LSxe7Ed9PP54ZpxOXhsVaxFJKgsXwoQJvkA/84wfVy0q1iKSRDZtgkGD/E0Ffv1ryM8PnSh5qFiLSFJwDoYMgbVr4bTTYMyY0ImSi4q1iCSFyZPhxRf9VfRmzYKmTUMnSi4q1iIS3IoVcMstfnryZOjWLWicpBRXsTazZ8xsnZltNbOVZjYk0cFEJDPs2OFPJy8pgWuugYEDQydKTvG2rO8Cujnn2gAXAXea2YmJiyUimWLkSFi+HI44Av7wh9Bpkldcxdo5t8I5V1rxMPrVPWGpRCQjvPwyTJoEzZrBs89Cq1ahEyWvuLvwzewRYDCQDbwPvFbFMkOBoQC5ubkUFBQ0SMj9VVRUFDxDstC+8AoLC4lEItoXUSGPi40bmzNkyElAM4YM+ZStW9cS8teS7H8j5pyLf2GzLOA0IB+4xzm3s7pl8/Ly3JIlS+odsD4KCgrI10BNQPuiQn5+PoWFhSxbtix0lKQQ6riIRODss+HNN+Gcc+C116BJ4OEOyfI3YmZLnXN5lefXafc45yLOuUXAd4EbGiqciGSW3/3OF+pOneCpp8IX6lSwv7uoKeqzFpH98M47cMcdfvqppyA3N2yeVFFrsTazTmY20MxamVmWmZ0DXAHMT3w8EUknW7f6YXqRiB9Xfe65oROljng+YHT4Lo/H8MV9DfBL59zLiQwmIunFObjhBvj8czj+eLjrrtCJUkutxdo5txE4sxGyiEgamzHDn0aek+OH6R1wQOhEqUXd+iKScJ9+6m92C/DQQ9CzZ9g8qUjFWkQSqqzM91MXFcHll/tTyqXuVKxFJKHuuAOWLIGuXf1FmnTXl/2jYi0iCfP6635MdVaW769u1y50otSlYi0iCbFxI/zkJ356zBg4/fSweVKdirWINDjnfN/0+vXQty/cfnvoRKlPxVpEGtxDD8GcOdC+vb/pbVZW6ESpT8VaRBrUsmX+GtUA06bBIYeEzZMuVKxFpMFs3+6H6ZWVwbBhcOmloROlDxVrEWkwt9wCH30ERx8NDzwQOk16UbEWkQbxwgswdao/jfy55/xp5dJwVKxFpN7+/W+47jo/fd99cNxxYfOkIxVrEamXXbvgqqugsBAuvHDPNUCkYalYi0i9TJgAixZB587wxBM6nTxRVKxFZL8tWgTjxvkC/cwz0LFj6ETpS8VaRPbL5s1w5ZVQXg6/+hX07x86UXpTsRaROnMOhg6FL76Ak0/2rWtJLBVrEamzadP8UL3Wrf3V9Jo1C50o/alYi0idfPgh3HSTn370UejePWyeTKFiLSJxKynxp5Pv2AFXX+2H7EnjULEWkbiNGgUffOBb05MmhU6TWVSsRSQuc+bAxInQtKm/O3nr1qETZRYVaxGp1bp1MHiwn54wAU46KWicjKRiLSI1Ki/3t+f65hs46yy49dbQiTKTirWI1Oj+++GNN/zZiU8/DU1UNYLQbheRar377p77J06f7q//IWGoWItIlbZt88P0du3y46ovuCB0osymYi0iVRo+HFatgl694J57QqcRFWsR2cesWb5/OjvbD9Nr0SJ0IlGxFpG9fPYZXH+9n544EY46Kmwe8VSsRWS3nTt9P/W2bXDZZTBkSOhEUkHFWkR2GzMG/vEPOOQQf/Nb3fUleahYiwgACxbA3Xf7cdQzZ0L79qETSSwVaxHhm2/8VfScgzvugDPOCJ1IKlOxFslwzsG118JXX0GfPjB6dOhEUhUVa5EM98gj8Mor0Lat7/5o2jR0IqlKrcXazA4ws2lmtsbMtpnZMjM7rzHCiUhiffZZS0aM8NNTp0LXrmHzSPXiaVk3Bb4AzgTaAqOB582sW+JiiUiiFRfD+PFHU1rqh+j9+MehE0lNan3D45zbDoyNmfWqmX0OnAisTkwsEUm0ESNg9eqWHHkkPPhg6DRSmzr3TplZLnAEsKKK54YCQwFyc3MpKCiob756KSoqCp4hWWhfeIWFhUQikYzfF2+/3ZHHHjuWpk0jjBjxPu++WxQ6UnDJ/jdizrn4FzZrBswFVjnnhtW0bF5enluyZEk949VPQUEB+fn5QTMkC+0LLz8/n8LCQpYtWxY6SjBr1/qLM23aBDfe+AkPP9wjdKSkkCx/I2a21DmXV3l+3KNBzKwJMAMoA4Y3YDYRaSSRCAwa5Av1+efDZZd9GTqSxCmuYm1mBkwDcoHLnHM7E5pKRBLirrtg4ULIzYUnn9Tp5Kkk3pb1o8BRwIXOuR0JzCMiCbJ4MYwd66effho6dQoaR+oonnHWXYFhQG9gvZkVRb+uSng6EWkQhYX+anqRCIwcCQMGhE4kdRXP0L01gN4siaQo5/z1qdesgbw8uPPO0Ilkf+h0c5E0N306zJ4NLVv6O8A0bx46kewPFWuRNLZyJfziF3560iTooVF6KUvFWiRNlZbCwIGwfTtceSX85CehE0l9qFiLpKnbb4f334dDD4VHH9UwvVSnYi2ShubNgwcegKws30/dpk3oRFJfKtYiaebrr+GnP/XT48fDqaeGzSMNQ8VaJI2Ul8PgwbBhA/TrB7fdFjqRNBQVa5E08uCDvgvkwANhxgzfDSLpQcVaJE289x6MGuWnp02DLl3C5pGGpWItkgaKivzp5Dt3wo03wsUXh04kDU3FWiQN3HyzPwHm2GPh3ntDp5FEULEWSXGzZ8MTT0CLFvDcc5CdHTqRJIKKtUgKW70ahg710w88AMccEzSOJJCKtUiK2rXLn0a+dStccom/sp6kLxVrkRQ1bpy/oUCXLvD44zqdPN2pWIukoIUL/XWpzeCZZ/y4aklvKtYiKWbTJn/TW+f8xZqS4Ibc0ghUrEVSiHMwZAisXQunnQZjxoROJI1FxVokhUyZAi++6K+iN2sWNGsWOpE0FhVrkRSxYgX88pd+evJk6NYtaBxpZCrWIimgpMSfTl5S4q+qN3Bg6ETS2FSsRVLAyJGwfLm/h+JDD4VOIyGoWIskuVdegYcf9v3Tzz0HrVqFTiQhqFiLJLEvv4RrrvHTd90FJ5wQNo+Eo2ItkqQiEX9H8m+/hQED4JZbQieSkFSsRZLUvffCggXQqRM89RQ00V9rRtOvXyQJvfMOjB7tp596Cr7znbB5JDwVa5Eks3WrH6YXifiuj3PPDZ1IkoGKtUiS+fnP4fPP4fjj/YeKIqBiLZJUZsyAmTMhJweefRYOOCB0IkkWKtYiSeLTT32rGvyJLz17hs0jyUXFWiQJlJX5fuqiIrj88j1jq0UqqFiLJIE77oAlS6BrV3+RJt31RSpTsRYJ7PXX4Xe/g6wsf9nTdu1CJ5JkpGItEtDGjf4sRfA3Ejj99LB5JHmpWIsE4pzvm16/Hvr29bfoEqlOXMXazIab2RIzKzWz6QnOJJIRHnoI5syB9u39TW+zskInkmTWNM7lvgLuBM4BshMXRyQzfPCBv0Y1wLRpcMghYfNI8ourWDvn/gxgZnnAdxOaSCTNbd/u7/RSVgbDhsGll4ZOJKkg3pZ1XMxsKDAUIDc3l4KCgoZcfZ0VFRUFz5AstC+8wsJCIpFI0H1x331H8NFHB9O163YuuWQpBQXlwbLouNgj2fdFgxZr59wUYApAXl6ey8/Pb8jV11lBQQGhMyQL7QuvXbt2FBYWBtsXL7zg+6kPOABefrkl3/te3yA5Kui42CPZ94VGg4g0kn//G667zk/fdx9873th80hqUbEWaQS7dsFVV0FhIVx4Idx4Y+hEkmri6gYxs6bRZbOALDNrAexyzu1KZDiRdDFhAixaBJ07wxNP6HRyqbt4W9ajgR3AKGBQdHp0okKJpJNFi2DcOF+gZ8yAjh1DJ5JUFO/QvbHA2IQmEUlDmzf77o/ychg1Cn7wg9CJJFWpz1okQZyDoUP9B4snn+xb1yL7S8VaJEGmTfND9Vq39lfTa9YsdCJJZSrWIgnw0Udw881++tFHoXv3sHkk9alYizSwkhJ/OnlxMVx9te+zFqkvFWuRBjZqlL9QU/fuMGlS6DSSLlSsRRrQa6/BxInQtKm/O3nr1qETSbpQsW4A+fn5DB8+PHQMCWzdOhg82E9PmAAnnRQ0jqSZjCjWgwcP5oc//GHoGJLGysv97bk2boSzzoJbbw2dSNJNRhRrkUS7/3544w1/duLTT0MT/WVJA8v4Q2rLli0MHTqUTp060bp1a84880yWLFmy+/lvv/2WK664gu9+97tkZ2dzzDHH8OSTT9a4zvnz59OuXTsee+yxRMeXJLBkyZ77J06f7q//IdLQMrpYO+e44IIL+PLLL3n11Vd5//336du3L/3792fdunUAlJSUcMIJJ/Dqq6+yYsUKbr75ZoYNG8b8+fOrXOcLL7zApZdeypQpU7j++usb8+VIANu2wRVX+Kvq3XQTXHBB6ESSrhr05gOp5s0332TZsmVs3LiR7Gx/a8nx48fzyiuvMGPGDG677Ta6dOnCyIqb5QFDhw5lwYIFPPvss/yg0oUepkyZwsiRI3nhhRcYMGBAo74WCWP4cPj0U+jVC+65J3QaSWcZXayXLl1KcXExBx100F7zS0pKWLVqFQCRSIS7776b2bNn8+WXX1JaWkpZWdk+d5R46aWXmDx5Mm+99RannXZaY70ECWjWLN8/nZ3th+m1aBE6kaSzjC7W5eXl5Obm8vbbb+/zXJs2bQC47777uP/++5k4cSLHHXccrVq14vbbb2fDhg17Ld+rVy+WL1/OtGnTOPXUUzFdsDitffYZVPRyTZwIRx0VNo+kv4wu1ieccAJff/01TZo04bDDDqtymUWLFnHhhRdy9dVXA76fe+XKlbRr126v5Q499FAeeugh8vPzGTp0KFOmTFHBTlM7d8KVV/r+6ssugyFDQieSTJAxHzBu3bqVZcuW7fV1+OGH06dPHy6++GLmzp3L559/zuLFixkzZszu1vYRRxzB/PnzWbRoER999BHDhw/n888/r3Ibhx12GG+++Sbz5s1j2LBhOOca8yVKIxkzBt55Bw45BKZO1V1fpHFkTLF+++23Of744/f6GjlyJK+99hr9+/fnuuuuo2fPnlx++eV8/PHHHHzwwQCMHj2ak08+mfPOO4++ffvSsmVLrqrhyjzdu3enoKCAuXPnqmCnoQUL4O67/TjqmTOhffvQiSRTZEQ3yPTp05k+fXq1z0+cOJGJEydW+Vz79u3585//XOP6CwoK9nrcvXt3vvjii7rGlCT3zTf+KnrOwW9+A2ecETqRZJKMaVmL1Idz8LOfwVdfQZ8+MFp3IJVGpmItEodHHoGXX4a2bX33R9OMeE8qyUTFWqQWy5fDiBF+eupU6No1bB7JTCrWIjXYscOfTl5a6ofo/fjHoRNJpkrpYl1cXMygQYOYM2dO6CiSpkaMgBUr4Mgj4cEHQ6eRTJayxXrDhg2ccsop/PGPf+Tyyy/f60p5Ig3hxRf9zW6bN/enk7dsGTqRZLKULNYrV66kd+/efPTRR5SVlVFcXMzZZ5/N6tWrQ0eTNLF27Z4zE++5B3r3DptHJOWK9d/+9jdOOukk1q9fz65du3bP37JlCxdddFHAZJIuIhEYNAg2bYLzz4ebbw6dSCTFivXs2bMZMGAAW7du3efMwOzsbG6vuAK8SD3cfTcsXAi5ufDkkzqdXJJDShRr5xx33XUX11xzDcXFxXs9Z2a0bt2aefPmMXDgwEAJJV0sXuyv/QH+8qedOoXNI1Ih6Yf2RyIRhg0bxrPPPsuOHTv2eq5p06Z07NiRgoICevbsGSihpIstW/zV9CIRGDkSdP8ISSZJXay3b9/OxRdfzOLFi/dpUbdo0YLu3buzYMECOqn5I/XkHAwbBqtXQ14e3Hln6EQie0vaYr1+/Xr69+/PZ599Rmlp6V7P5eTk0KdPH1566SVycnICJZR0Mn06zJ7th+fNmuWH64kkk6Tss/7www/p1asXn3zySZWFetCgQcydO1eFWhrEypXwi1/46UmToEePsHlEqpJ0xfqtt97ilFNOYcOGDXsNzQM/4uO3v/0tkydPJisrK1BCSSelpf508u3bfX/1T34SOpFI1YIU6yVLlnDKKadQWFi41/yZM2dy7rnnsm3btn1+Jicnh6eeeopbb721sWJKBvj1r+G99+DQQ/3ZihqmJ8kqSLGeMGECS5Ys4ZxzzqGsrAznHOPHj+e6667bZ4YTrSEAAAfzSURBVMSHmdGmTRveeOMNfqyr6EgDmjcP7r8fsrJ8P3X0HskiSanRP2DcuHEjc+fOpby8nOXLl3PllVfSqlUr/vjHP+5TqJs1a8ZBBx1EQUEBPdSRKA3o66/hpz/10+PGwamnhs0jUptGL9aPP/747rt+79ixg7lz5wJUOTSvR48ezJ8/n4MOOqixY0qaGzwYNmyAfv3gV78KnUakdnF1g5hZBzN70cy2m9kaM7tyfzZWXl7OxIkTKSkp2T2vuLh4n0Kdk5NDv379eOedd1SopcFt2HAA8+bBgQfCjBm+G0Qk2cXbsp4ElAG5QG9gjpl94JxbUZeN/fWvf2X79u01LpOTk8M111zDH/7wB5o0SbrBKpJidu2CwkJ/UabNm/0wvXXrsgGYNg26dAkcUCROVvmCSPssYNYS2Awc65xbGZ03A/jSOTequp9r3bq1O/HEE/ea98EHH+wzAiRWkyZN6Ny5M4cffnj8r6AGhYWFtGvXrkHWlepSfV9EIr7w7toFO3dW/b2qeZFI5TUtA6BHj94cfHCjv4ykk+rHRUNKln2xcOHCpc65vMrz42lZHwHsqijUUR8AZ1Ze0MyGAkPBfzgYW5jLysrYsmVLjRsqLy9n/fr1tGnThuYNcApZJBKp8Z9DJkmGfeEcRCIW89WEXbv2PK5uOhJpQi1tihplZbndX2VljmbNIuTkFKJDIzmOi2SR7PsinmLdCthaad4WoHXlBZ1zU4ApAHl5eS727i2jRo1i1apVlJWV1brB0tJSFi9eTNu2beOIV72CggLy8/PrtY500VD7wjl/X8KKboVNm+KfruV/dY2ys6FDB2jf3n+Pd7pNG4jtTcvPz6ewsJBly5bVe1+kA/2N7JEs+8KqGewfT7EuAiqPQG0D7HvmSjV27tzJY489FlehLi8vZ82aNYwbN477778/3k1IHUUivnjWpdhWPK50BYC4mUG7dnUrthWPW7Ro2NcvkmriKdYrgaZm1sM590l0Xi8g7g8XX3rpJSL7dh7u1rp1a0pLS+ncuTPnn38+5513Hv369Yt39RmtqlZuVQV31arv4dye+Vu2sN9dCwcc4EdS1LWV27bt3q1cEYlfrcXaObfdzP4MjDOzIfjRIBcDp8e7kXvuuYeioqLdj1u2bEkkEqFt27YMGDCACy64gH79+mXspU4rWrl17VbYvBliRkHWosNej+rTys3ObvBdICK1iHfo3s+BJ4ANwLfADfEO2/vkk09YunQp2dnZNG/enP79+3PRRRfRr18/unbtup+xk1NJSd2L7aZNfmjZ/rZymzevuZVb8fiLLz6gX79eu59r21bji0VSSVzF2jm3CbhkfzZw4IEHMnXqVL7//e/Ts2fPajvPk0V5efyt3MqP42/l7qtt25qLbXXT2dnxXXyooGAzJ520//lEJKyEn27eoUMHhgwZkujN7KOkBL79tjkrVtTenxs7vXlz/Vq5dS22HTr47gi1ckWkJkl7pxjwrdytW/dvmJi/JlTc3ep7adOmbsW2YjonR5fYFJHEaJRiXVq6fx+ebd7sC/b+aNYMWrUq4zvfaV6nUQvt2kHTpP4XJiKZKGFl6V//gkMO8YW30nWa6qRNm7oPEevQwbdyFy78e1IMchcRqa+EFesdO2Dt2uhGmu7fELF27XwLWUQk0yWsWB91lL8TR4cO/o7R6ssVEdl/CSvWOTnwH/+RqLWLiGQWnfwrIpICVKxFRFKAirWISApQsRYRSQEq1iIiKUDFWkQkBahYi4ikABVrEZEUoGItIpICzO3vxZtrW7HZRmBNQlYev47AN4EzJAvtiz20L/bQvtgjWfZFV+fcQZVnJqxYJwMzW+KcywudIxloX+yhfbGH9sUeyb4v1A0iIpICVKxFRFJAuhfrKaEDJBHtiz20L/bQvtgjqfdFWvdZi4iki3RvWYuIpAUVaxGRFKBiLSKSAjKqWJtZDzMrMbNnQmcJwcwOMLNpZrbGzLaZ2TIzOy90rsZiZh3M7EUz2x7dB1eGzhRCph8H1Un2+pBRxRqYBLwbOkRATYEvgDOBtsBo4Hkz6xYwU2OaBJQBucBVwKNmdkzYSEFk+nFQnaSuDxlTrM1sIFAIzA+dJRTn3Hbn3Fjn3GrnXLlz7lXgc+DE0NkSzcxaApcBdzjnipxzi4CXgavDJmt8mXwcVCcV6kNGFGszawOMA/4zdJZkYma5wBHAitBZGsERwC7n3MqYeR8Amdiy3kuGHQf7SJX6kBHFGhgPTHPOrQ0dJFmYWTNgJvCUc+6j0HkaQStga6V5W4DWAbIkjQw8DqqSEvUh5Yu1mRWYmavma5GZ9QbOAn4fOmui1bYvYpZrAszA998ODxa4cRUBbSrNawNsC5AlKWTocbCXVKoPTUMHqC/nXH5Nz5vZL4FuwL/NDHwLK8vMjnbOnZDwgI2otn0BYH4nTMN/yHa+c25nonMliZVAUzPr4Zz7JDqvF5n71j9Tj4PK8kmR+pD2p5ubWQ57t6huxf9ybnDObQwSKiAzewzoDZzlnCsKnacxmdlzgAOG4PfBa8DpzrmMK9iZfBzESqX6kPIt69o454qB4orHZlYElCTbL6IxmFlXYBhQCqyPtiQAhjnnZgYL1nh+DjwBbAC+xf9BZmKhzvTjYLdUqg9p37IWEUkHKf8Bo4hIJlCxFhFJASrWIiIpQMVaRCQFqFiLiKQAFWsRkRSgYi0ikgJUrEVEUsD/B/fVMkeuiJ/dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following code outputs a Leaky ReLU plot:\n",
    "\n",
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)\n",
    "\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "plt.savefig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Leaky ReLU in TensorFlow:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a neural network on MNIST using the leaky ReLU. First let's create the graph:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2= 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the data:\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.9048\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.9508\n",
      "10 Batch accuracy: 0.92 Validation accuracy: 0.966\n",
      "15 Batch accuracy: 1.0 Validation accuracy: 0.9724\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9746\n",
      "25 Batch accuracy: 0.98 Validation accuracy: 0.9762\n",
      "30 Batch accuracy: 1.0 Validation accuracy: 0.9784\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "            \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.savefig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELU stands for Self-Normalizing Exponential Linear Unit. In a paper about this, it proposes that during training, a deep neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize.\n",
    "# Self-normalization means that the output of each layer will tend to preserve the same mean and variance  during tranining.\n",
    "    # This solves the vanishing/exploding gradients problem. As a result this activation significantly outperforms the other activation functions significantly.\n",
    "# Unfortunately, the self-normalizing property of the SELU is easily broken when using nonsequential topologies?! \n",
    "    # If it is broken, SELU will perform no better then the other activation functions.\n",
    "    \n",
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "plt.savefig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=alpha_0_1, alpha=scale_0_1):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))\n",
    "\n",
    "# Note that the SELU activation function cannot be used along with regular Dropout.\n",
    "# Fortunately there is a Dropout Variant called Alpha Dropout. It is available in tf.contrib.nn.alpha_dropout().\n",
    "\n",
    "# Let's create a neural net for MNIST using the SELU activation function:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.94 Validation accuracy: 0.9388\n",
      "5 Batch accuracy: 0.98 Validation accuracy: 0.9634\n",
      "10 Batch accuracy: 1.0 Validation accuracy: 0.9694\n",
      "15 Batch accuracy: 1.0 Validation accuracy: 0.9706\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9694\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.9696\n",
      "30 Batch accuracy: 1.0 Validation accuracy: 0.9706\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "# Now let's train it. Don't forget to scale the inputs to mean 0 and standard deviation 1:\n",
    "\n",
    "\n",
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using HE initialization along with ELU (or any variant of ReLU) can significantly reduce the vanishing/exploding gradients problems at the beginning of training.\n",
    "# However it doesn't guarantee that they won't come back during training.\n",
    "# Batch normalization is extremely effective for Deep Neural Networks. The vanishing gradients problems was greatly reduced, even when using saturating functions such as tanh and logistic functions.\n",
    "# Batch normalization is one of the best techniques for improving accuracy of ML models.\n",
    "# One downside is that Batch Normalization does add some complexity to the model. There is a slower runtime for predictions.\n",
    "# If you need predictions to be lightning fast, you might want to check how well plain Exponential Linear Unit Activation + HE Initialization perform before playing with Batch Normalization.\n",
    "\n",
    "# TensorFlow provides a tf.nn.batch_normalization() function:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid repeating the same parameters over and over again, we can use Python's partial() function.\n",
    "# Repetition is a problem when having to program for many layers:\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a neural net for MNIST, using the ELU activation function and Batch Normalization at each layer:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are using tf.layers.batch_normalization() rather than tf.contrib.layers.batch_norm() as in the book,\n",
    "# we need to explicitly run the extra update operations needed by batch normalization(sess.run([training_op, extra_update_ops,...]))\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9018\n",
      "1 Validation accuracy: 0.9268\n",
      "2 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9608\n",
      "7 Validation accuracy: 0.9628\n",
      "8 Validation accuracy: 0.9654\n",
      "9 Validation accuracy: 0.9678\n",
      "10 Validation accuracy: 0.9686\n",
      "11 Validation accuracy: 0.969\n",
      "12 Validation accuracy: 0.9678\n",
      "13 Validation accuracy: 0.971\n",
      "14 Validation accuracy: 0.9712\n",
      "15 Validation accuracy: 0.9722\n",
      "16 Validation accuracy: 0.9736\n",
      "17 Validation accuracy: 0.9732\n",
      "18 Validation accuracy: 0.9742\n",
      "19 Validation accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                    feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For MNIST, this isn't great accuracy. The network is too shallow so Batch Norm and ELU are unlikely to have a very positive impact.\n",
    "# Batch Norm and ELU do the best for much deeper nets.\n",
    "\n",
    "# We could also make the training operation depend on the update operations. This way, you would just have to evaluate the training_op during training, Tensorflow would automatically run update operations as well.\n",
    "\n",
    "# One more thing: notice that the list of trainable variables is shorter than the list of all global variables.\n",
    "# This is because the moving averages are non-trainable variables. If you want to reuse a pretrained neural network, you musn't forget these non-trainable variables.\n",
    "\n",
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A popular technique to lessen the exploding gradients problem is to simply clip the gradients during backpropagation so that they never exceed some threshold.\n",
    "# In general, people now prefer Batch Normalization, but it's still good to know Gradient Clipping.\n",
    "\n",
    "# Let's create a simple neural net for MNIST and add gradient clipping:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's apply gradient clipping. For this, we need to get the gradients, use the clip_by_value() function to clip them, then we apply them:\n",
    "\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var) for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same as usual:\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.288\n",
      "1 Validation accuracy: 0.7936\n",
      "2 Validation accuracy: 0.8798\n",
      "3 Validation accuracy: 0.9062\n",
      "4 Validation accuracy: 0.9164\n",
      "5 Validation accuracy: 0.9218\n",
      "6 Validation accuracy: 0.9292\n",
      "7 Validation accuracy: 0.9358\n",
      "8 Validation accuracy: 0.9382\n",
      "9 Validation accuracy: 0.9414\n",
      "10 Validation accuracy: 0.9458\n",
      "11 Validation accuracy: 0.947\n",
      "12 Validation accuracy: 0.9476\n",
      "13 Validation accuracy: 0.9536\n",
      "14 Validation accuracy: 0.9566\n",
      "15 Validation accuracy: 0.9566\n",
      "16 Validation accuracy: 0.9578\n",
      "17 Validation accuracy: 0.959\n",
      "18 Validation accuracy: 0.9622\n",
      "19 Validation accuracy: 0.9616\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing a TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's generally not a good idea to train a very large DNN from scratch. Better to find an existing neural network that performs a similar task to the one we're trying to tackle.\n",
    "# Usually, we will try to reuse the lower level layers because they are more vague and general.\n",
    "# If the original model was trained using TensorFlow, we can simply restore it and train it on a new rask.\n",
    "# We can use the import_meta_graph() function to import the operations into a default graph. \n",
    "# This returns a Saver that you can later use to load the model's state:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/Const\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/RestoreV2_1/tensor_names\n",
      "save/RestoreV2_1/shape_and_slices\n",
      "save/RestoreV2_1\n",
      "save/Assign_1\n",
      "save/RestoreV2_2/tensor_names\n",
      "save/RestoreV2_2/shape_and_slices\n",
      "save/RestoreV2_2\n",
      "save/Assign_2\n",
      "save/RestoreV2_3/tensor_names\n",
      "save/RestoreV2_3/shape_and_slices\n",
      "save/RestoreV2_3\n",
      "save/Assign_3\n",
      "save/RestoreV2_4/tensor_names\n",
      "save/RestoreV2_4/shape_and_slices\n",
      "save/RestoreV2_4\n",
      "save/Assign_4\n",
      "save/RestoreV2_5/tensor_names\n",
      "save/RestoreV2_5/shape_and_slices\n",
      "save/RestoreV2_5\n",
      "save/Assign_5\n",
      "save/RestoreV2_6/tensor_names\n",
      "save/RestoreV2_6/shape_and_slices\n",
      "save/RestoreV2_6\n",
      "save/Assign_6\n",
      "save/RestoreV2_7/tensor_names\n",
      "save/RestoreV2_7/shape_and_slices\n",
      "save/RestoreV2_7\n",
      "save/Assign_7\n",
      "save/RestoreV2_8/tensor_names\n",
      "save/RestoreV2_8/shape_and_slices\n",
      "save/RestoreV2_8\n",
      "save/Assign_8\n",
      "save/RestoreV2_9/tensor_names\n",
      "save/RestoreV2_9/shape_and_slices\n",
      "save/RestoreV2_9\n",
      "save/Assign_9\n",
      "save/RestoreV2_10/tensor_names\n",
      "save/RestoreV2_10/shape_and_slices\n",
      "save/RestoreV2_10\n",
      "save/Assign_10\n",
      "save/RestoreV2_11/tensor_names\n",
      "save/RestoreV2_11/shape_and_slices\n",
      "save/RestoreV2_11\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "# Next we need to get a list of operations in that collection if we don't already know them:\n",
    "# We'll usually have to do this if the pretrained model isn't well documented... We'll have to explore manually.\n",
    "\n",
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you know which operations you need, you can get a handle on them using the graph's get_operation_by_name() or get_tensor_by_name() methods:\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are the author of the original model, you could make things easier for people who will reuse your model by giving operations very clear names and documenting them.\n",
    "# Another approach is to create a collection containing all the important operations that people will want to get a handle on:\n",
    "\n",
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This way, people who reuse your model will be able to simply write:\n",
    "\n",
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Now we can start a session, restore the model's state and continue training on your data:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # Continue training the model...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9644\n",
      "1 Validation accuracy: 0.9628\n",
      "2 Validation accuracy: 0.9652\n",
      "3 Validation accuracy: 0.9654\n",
      "4 Validation accuracy: 0.9644\n",
      "5 Validation accuracy: 0.9652\n",
      "6 Validation accuracy: 0.9688\n",
      "7 Validation accuracy: 0.9688\n",
      "8 Validation accuracy: 0.968\n",
      "9 Validation accuracy: 0.9688\n",
      "10 Validation accuracy: 0.9704\n",
      "11 Validation accuracy: 0.9714\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9708\n",
      "15 Validation accuracy: 0.9724\n",
      "16 Validation accuracy: 0.972\n",
      "17 Validation accuracy: 0.9714\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "# Now let's test the model on real data:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    saver_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you could have access to the Python code that built the original graph.\n",
    "# We can use the original code instead of import_meta_graph().\n",
    "# In general, we want to reuse only part of the original model, typically the lower layers.\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9644\n",
      "1 Validation accuracy: 0.9628\n",
      "2 Validation accuracy: 0.9652\n",
      "3 Validation accuracy: 0.9654\n",
      "4 Validation accuracy: 0.9644\n",
      "5 Validation accuracy: 0.9652\n",
      "6 Validation accuracy: 0.9688\n",
      "7 Validation accuracy: 0.9688\n",
      "8 Validation accuracy: 0.968\n",
      "9 Validation accuracy: 0.9688\n",
      "10 Validation accuracy: 0.9704\n",
      "11 Validation accuracy: 0.9714\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9708\n",
      "15 Validation accuracy: 0.9724\n",
      "16 Validation accuracy: 0.972\n",
      "17 Validation accuracy: 0.9714\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "# Now we can train this new model that was created from reused parts of a preexisting NN:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In general, we will want to reuse only the lower layers of the original model since it is the most basic and least specific part.\n",
    "# If we use import_meta_graph(), it will load the whole graph, but we can simply ignore the parts we don't need.\n",
    "# In this example, we add a new 4th hidden layer on top of the pretrained 3rd layer (ignoring the 4th hidden layer).\n",
    "# We also build a new output layer, the loss for this new output, and a new optimizer to minimize it.\n",
    "# We also need another saver to save the whole graph, and initialization operation to initialize all the new variables:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # new layer\n",
    "n_outputs = 10  # new layer\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.1186\n",
      "0 Validation accuracy: 0.1714\n",
      "0 Validation accuracy: 0.1934\n",
      "0 Validation accuracy: 0.2122\n",
      "0 Validation accuracy: 0.2268\n",
      "0 Validation accuracy: 0.2214\n",
      "0 Validation accuracy: 0.2214\n",
      "0 Validation accuracy: 0.2154\n",
      "0 Validation accuracy: 0.2238\n",
      "0 Validation accuracy: 0.2384\n",
      "0 Validation accuracy: 0.2512\n",
      "0 Validation accuracy: 0.278\n",
      "0 Validation accuracy: 0.287\n",
      "0 Validation accuracy: 0.2862\n",
      "0 Validation accuracy: 0.3046\n",
      "0 Validation accuracy: 0.3048\n",
      "0 Validation accuracy: 0.3218\n",
      "0 Validation accuracy: 0.3324\n",
      "0 Validation accuracy: 0.3446\n",
      "0 Validation accuracy: 0.3578\n",
      "0 Validation accuracy: 0.3624\n",
      "0 Validation accuracy: 0.3672\n",
      "0 Validation accuracy: 0.379\n",
      "0 Validation accuracy: 0.3864\n",
      "0 Validation accuracy: 0.3942\n",
      "0 Validation accuracy: 0.4026\n",
      "0 Validation accuracy: 0.3978\n",
      "0 Validation accuracy: 0.4066\n",
      "0 Validation accuracy: 0.4148\n",
      "0 Validation accuracy: 0.4094\n",
      "0 Validation accuracy: 0.4108\n",
      "0 Validation accuracy: 0.419\n",
      "0 Validation accuracy: 0.4196\n",
      "0 Validation accuracy: 0.4276\n",
      "0 Validation accuracy: 0.4324\n",
      "0 Validation accuracy: 0.4366\n",
      "0 Validation accuracy: 0.446\n",
      "0 Validation accuracy: 0.4534\n",
      "0 Validation accuracy: 0.4582\n",
      "0 Validation accuracy: 0.4764\n",
      "0 Validation accuracy: 0.4766\n",
      "0 Validation accuracy: 0.478\n",
      "0 Validation accuracy: 0.4822\n",
      "0 Validation accuracy: 0.4828\n",
      "0 Validation accuracy: 0.4904\n",
      "0 Validation accuracy: 0.4894\n",
      "0 Validation accuracy: 0.4902\n",
      "0 Validation accuracy: 0.492\n",
      "0 Validation accuracy: 0.5036\n",
      "0 Validation accuracy: 0.5082\n",
      "0 Validation accuracy: 0.5188\n",
      "0 Validation accuracy: 0.5308\n",
      "0 Validation accuracy: 0.5348\n",
      "0 Validation accuracy: 0.5312\n",
      "0 Validation accuracy: 0.537\n",
      "0 Validation accuracy: 0.5392\n",
      "0 Validation accuracy: 0.5394\n",
      "0 Validation accuracy: 0.5474\n",
      "0 Validation accuracy: 0.551\n",
      "0 Validation accuracy: 0.5594\n",
      "0 Validation accuracy: 0.5602\n",
      "0 Validation accuracy: 0.568\n",
      "0 Validation accuracy: 0.5724\n",
      "0 Validation accuracy: 0.5774\n",
      "0 Validation accuracy: 0.5772\n",
      "0 Validation accuracy: 0.5772\n",
      "0 Validation accuracy: 0.5868\n",
      "0 Validation accuracy: 0.5966\n",
      "0 Validation accuracy: 0.6028\n",
      "0 Validation accuracy: 0.6048\n",
      "0 Validation accuracy: 0.6134\n",
      "0 Validation accuracy: 0.6124\n",
      "0 Validation accuracy: 0.609\n",
      "0 Validation accuracy: 0.6106\n",
      "0 Validation accuracy: 0.6134\n",
      "0 Validation accuracy: 0.6282\n",
      "0 Validation accuracy: 0.635\n",
      "0 Validation accuracy: 0.6394\n",
      "0 Validation accuracy: 0.6456\n",
      "0 Validation accuracy: 0.647\n",
      "0 Validation accuracy: 0.6498\n",
      "0 Validation accuracy: 0.6526\n",
      "0 Validation accuracy: 0.6532\n",
      "0 Validation accuracy: 0.6674\n",
      "0 Validation accuracy: 0.6728\n",
      "0 Validation accuracy: 0.6636\n",
      "0 Validation accuracy: 0.677\n",
      "0 Validation accuracy: 0.6834\n",
      "0 Validation accuracy: 0.686\n",
      "0 Validation accuracy: 0.6822\n",
      "0 Validation accuracy: 0.6862\n",
      "0 Validation accuracy: 0.6842\n",
      "0 Validation accuracy: 0.6866\n",
      "0 Validation accuracy: 0.6936\n",
      "0 Validation accuracy: 0.701\n",
      "0 Validation accuracy: 0.6998\n",
      "0 Validation accuracy: 0.7006\n",
      "0 Validation accuracy: 0.6976\n",
      "0 Validation accuracy: 0.7122\n",
      "0 Validation accuracy: 0.7212\n",
      "0 Validation accuracy: 0.7162\n",
      "0 Validation accuracy: 0.725\n",
      "0 Validation accuracy: 0.7376\n",
      "0 Validation accuracy: 0.7336\n",
      "0 Validation accuracy: 0.7286\n",
      "0 Validation accuracy: 0.7414\n",
      "0 Validation accuracy: 0.744\n",
      "0 Validation accuracy: 0.7418\n",
      "0 Validation accuracy: 0.7436\n",
      "0 Validation accuracy: 0.7446\n",
      "0 Validation accuracy: 0.7536\n",
      "0 Validation accuracy: 0.7598\n",
      "0 Validation accuracy: 0.7614\n",
      "0 Validation accuracy: 0.7594\n",
      "0 Validation accuracy: 0.763\n",
      "0 Validation accuracy: 0.7678\n",
      "0 Validation accuracy: 0.7724\n",
      "0 Validation accuracy: 0.7736\n",
      "0 Validation accuracy: 0.7704\n",
      "0 Validation accuracy: 0.7762\n",
      "0 Validation accuracy: 0.7768\n",
      "0 Validation accuracy: 0.7738\n",
      "0 Validation accuracy: 0.7706\n",
      "0 Validation accuracy: 0.7704\n",
      "0 Validation accuracy: 0.7766\n",
      "0 Validation accuracy: 0.7796\n",
      "0 Validation accuracy: 0.79\n",
      "0 Validation accuracy: 0.7924\n",
      "0 Validation accuracy: 0.794\n",
      "0 Validation accuracy: 0.7938\n",
      "0 Validation accuracy: 0.798\n",
      "0 Validation accuracy: 0.8052\n",
      "0 Validation accuracy: 0.7962\n",
      "0 Validation accuracy: 0.7946\n",
      "0 Validation accuracy: 0.8076\n",
      "0 Validation accuracy: 0.8128\n",
      "0 Validation accuracy: 0.8084\n",
      "0 Validation accuracy: 0.8182\n",
      "0 Validation accuracy: 0.8082\n",
      "0 Validation accuracy: 0.8184\n",
      "0 Validation accuracy: 0.8164\n",
      "0 Validation accuracy: 0.8188\n",
      "0 Validation accuracy: 0.8152\n",
      "0 Validation accuracy: 0.8094\n",
      "0 Validation accuracy: 0.8102\n",
      "0 Validation accuracy: 0.8182\n",
      "0 Validation accuracy: 0.8164\n",
      "0 Validation accuracy: 0.8204\n",
      "0 Validation accuracy: 0.832\n",
      "0 Validation accuracy: 0.8258\n",
      "0 Validation accuracy: 0.8272\n",
      "0 Validation accuracy: 0.8276\n",
      "0 Validation accuracy: 0.8272\n",
      "0 Validation accuracy: 0.819\n",
      "0 Validation accuracy: 0.834\n",
      "0 Validation accuracy: 0.8294\n",
      "0 Validation accuracy: 0.8294\n",
      "0 Validation accuracy: 0.8386\n",
      "0 Validation accuracy: 0.8396\n",
      "0 Validation accuracy: 0.8406\n",
      "0 Validation accuracy: 0.844\n",
      "0 Validation accuracy: 0.8484\n",
      "0 Validation accuracy: 0.8484\n",
      "0 Validation accuracy: 0.8492\n",
      "0 Validation accuracy: 0.8508\n",
      "0 Validation accuracy: 0.849\n",
      "0 Validation accuracy: 0.8486\n",
      "0 Validation accuracy: 0.8518\n",
      "0 Validation accuracy: 0.855\n",
      "0 Validation accuracy: 0.8534\n",
      "0 Validation accuracy: 0.8496\n",
      "0 Validation accuracy: 0.8466\n",
      "0 Validation accuracy: 0.836\n",
      "0 Validation accuracy: 0.8486\n",
      "0 Validation accuracy: 0.8494\n",
      "0 Validation accuracy: 0.8546\n",
      "0 Validation accuracy: 0.8582\n",
      "0 Validation accuracy: 0.8578\n",
      "0 Validation accuracy: 0.8464\n",
      "0 Validation accuracy: 0.8606\n",
      "0 Validation accuracy: 0.8602\n",
      "0 Validation accuracy: 0.8558\n",
      "0 Validation accuracy: 0.8582\n",
      "0 Validation accuracy: 0.8618\n",
      "0 Validation accuracy: 0.8606\n",
      "0 Validation accuracy: 0.863\n",
      "0 Validation accuracy: 0.8672\n",
      "0 Validation accuracy: 0.8644\n",
      "0 Validation accuracy: 0.8592\n",
      "0 Validation accuracy: 0.8624\n",
      "0 Validation accuracy: 0.865\n",
      "0 Validation accuracy: 0.8578\n",
      "0 Validation accuracy: 0.8666\n",
      "0 Validation accuracy: 0.8698\n",
      "0 Validation accuracy: 0.8668\n",
      "0 Validation accuracy: 0.8682\n",
      "0 Validation accuracy: 0.864\n",
      "0 Validation accuracy: 0.8656\n",
      "0 Validation accuracy: 0.8674\n",
      "0 Validation accuracy: 0.8704\n",
      "0 Validation accuracy: 0.8716\n",
      "0 Validation accuracy: 0.8718\n",
      "0 Validation accuracy: 0.8768\n",
      "0 Validation accuracy: 0.8726\n",
      "0 Validation accuracy: 0.8768\n",
      "0 Validation accuracy: 0.87\n",
      "0 Validation accuracy: 0.8702\n",
      "0 Validation accuracy: 0.873\n",
      "0 Validation accuracy: 0.8758\n",
      "0 Validation accuracy: 0.8754\n",
      "0 Validation accuracy: 0.875\n",
      "0 Validation accuracy: 0.8722\n",
      "0 Validation accuracy: 0.8752\n",
      "0 Validation accuracy: 0.8766\n",
      "0 Validation accuracy: 0.8764\n",
      "0 Validation accuracy: 0.8718\n",
      "0 Validation accuracy: 0.876\n",
      "0 Validation accuracy: 0.8772\n",
      "0 Validation accuracy: 0.8804\n",
      "0 Validation accuracy: 0.8848\n",
      "0 Validation accuracy: 0.8836\n",
      "0 Validation accuracy: 0.8784\n",
      "0 Validation accuracy: 0.8846\n",
      "0 Validation accuracy: 0.882\n",
      "0 Validation accuracy: 0.8798\n",
      "0 Validation accuracy: 0.878\n",
      "0 Validation accuracy: 0.8864\n",
      "0 Validation accuracy: 0.8882\n",
      "0 Validation accuracy: 0.8818\n",
      "0 Validation accuracy: 0.8866\n",
      "0 Validation accuracy: 0.8838\n",
      "0 Validation accuracy: 0.8848\n",
      "0 Validation accuracy: 0.8874\n",
      "0 Validation accuracy: 0.8854\n",
      "0 Validation accuracy: 0.8834\n",
      "0 Validation accuracy: 0.8844\n",
      "0 Validation accuracy: 0.8866\n",
      "0 Validation accuracy: 0.8864\n",
      "0 Validation accuracy: 0.889\n",
      "0 Validation accuracy: 0.8896\n",
      "0 Validation accuracy: 0.8914\n",
      "0 Validation accuracy: 0.8866\n",
      "0 Validation accuracy: 0.8904\n",
      "0 Validation accuracy: 0.8892\n",
      "0 Validation accuracy: 0.8894\n",
      "0 Validation accuracy: 0.89\n",
      "0 Validation accuracy: 0.888\n",
      "0 Validation accuracy: 0.8924\n",
      "0 Validation accuracy: 0.8896\n",
      "0 Validation accuracy: 0.8904\n",
      "0 Validation accuracy: 0.8918\n",
      "0 Validation accuracy: 0.8888\n",
      "0 Validation accuracy: 0.8932\n",
      "0 Validation accuracy: 0.892\n",
      "0 Validation accuracy: 0.8916\n",
      "0 Validation accuracy: 0.8936\n",
      "0 Validation accuracy: 0.8914\n",
      "0 Validation accuracy: 0.8916\n",
      "0 Validation accuracy: 0.8932\n",
      "0 Validation accuracy: 0.8958\n",
      "0 Validation accuracy: 0.8922\n",
      "0 Validation accuracy: 0.8942\n",
      "0 Validation accuracy: 0.8968\n",
      "0 Validation accuracy: 0.8958\n",
      "0 Validation accuracy: 0.8938\n",
      "0 Validation accuracy: 0.8934\n",
      "0 Validation accuracy: 0.8924\n",
      "0 Validation accuracy: 0.895\n",
      "0 Validation accuracy: 0.8962\n",
      "0 Validation accuracy: 0.8958\n",
      "0 Validation accuracy: 0.897\n",
      "0 Validation accuracy: 0.8986\n",
      "0 Validation accuracy: 0.9002\n",
      "0 Validation accuracy: 0.9\n",
      "0 Validation accuracy: 0.8982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Validation accuracy: 0.8972\n",
      "1 Validation accuracy: 0.8974\n",
      "1 Validation accuracy: 0.8966\n",
      "1 Validation accuracy: 0.9002\n",
      "1 Validation accuracy: 0.8972\n",
      "1 Validation accuracy: 0.898\n",
      "1 Validation accuracy: 0.899\n",
      "1 Validation accuracy: 0.9022\n",
      "1 Validation accuracy: 0.9022\n",
      "1 Validation accuracy: 0.8992\n",
      "1 Validation accuracy: 0.9008\n",
      "1 Validation accuracy: 0.8994\n",
      "1 Validation accuracy: 0.9026\n",
      "1 Validation accuracy: 0.9008\n",
      "1 Validation accuracy: 0.9012\n",
      "1 Validation accuracy: 0.9016\n",
      "1 Validation accuracy: 0.897\n",
      "1 Validation accuracy: 0.899\n",
      "1 Validation accuracy: 0.9042\n",
      "1 Validation accuracy: 0.899\n",
      "1 Validation accuracy: 0.8972\n",
      "1 Validation accuracy: 0.8988\n",
      "1 Validation accuracy: 0.902\n",
      "1 Validation accuracy: 0.8988\n",
      "1 Validation accuracy: 0.9016\n",
      "1 Validation accuracy: 0.9032\n",
      "1 Validation accuracy: 0.9044\n",
      "1 Validation accuracy: 0.9058\n",
      "1 Validation accuracy: 0.9028\n",
      "1 Validation accuracy: 0.9016\n",
      "1 Validation accuracy: 0.9054\n",
      "1 Validation accuracy: 0.9054\n",
      "1 Validation accuracy: 0.9014\n",
      "1 Validation accuracy: 0.905\n",
      "1 Validation accuracy: 0.9062\n",
      "1 Validation accuracy: 0.907\n",
      "1 Validation accuracy: 0.905\n",
      "1 Validation accuracy: 0.9022\n",
      "1 Validation accuracy: 0.9026\n",
      "1 Validation accuracy: 0.9066\n",
      "1 Validation accuracy: 0.9086\n",
      "1 Validation accuracy: 0.9088\n",
      "1 Validation accuracy: 0.9084\n",
      "1 Validation accuracy: 0.9088\n",
      "1 Validation accuracy: 0.9056\n",
      "1 Validation accuracy: 0.9054\n",
      "1 Validation accuracy: 0.9058\n",
      "1 Validation accuracy: 0.9048\n",
      "1 Validation accuracy: 0.9048\n",
      "1 Validation accuracy: 0.9098\n",
      "1 Validation accuracy: 0.906\n",
      "1 Validation accuracy: 0.9082\n",
      "1 Validation accuracy: 0.9092\n",
      "1 Validation accuracy: 0.9048\n",
      "1 Validation accuracy: 0.9092\n",
      "1 Validation accuracy: 0.9078\n",
      "1 Validation accuracy: 0.9074\n",
      "1 Validation accuracy: 0.9104\n",
      "1 Validation accuracy: 0.9106\n",
      "1 Validation accuracy: 0.9104\n",
      "1 Validation accuracy: 0.9092\n",
      "1 Validation accuracy: 0.9078\n",
      "1 Validation accuracy: 0.912\n",
      "1 Validation accuracy: 0.909\n",
      "1 Validation accuracy: 0.9114\n",
      "1 Validation accuracy: 0.9092\n",
      "1 Validation accuracy: 0.9094\n",
      "1 Validation accuracy: 0.9078\n",
      "1 Validation accuracy: 0.9078\n",
      "1 Validation accuracy: 0.9104\n",
      "1 Validation accuracy: 0.9104\n",
      "1 Validation accuracy: 0.9058\n",
      "1 Validation accuracy: 0.9088\n",
      "1 Validation accuracy: 0.9106\n",
      "1 Validation accuracy: 0.9098\n",
      "1 Validation accuracy: 0.912\n",
      "1 Validation accuracy: 0.91\n",
      "1 Validation accuracy: 0.913\n",
      "1 Validation accuracy: 0.9134\n",
      "1 Validation accuracy: 0.9126\n",
      "1 Validation accuracy: 0.9134\n",
      "1 Validation accuracy: 0.9118\n",
      "1 Validation accuracy: 0.9104\n",
      "1 Validation accuracy: 0.91\n",
      "1 Validation accuracy: 0.9102\n",
      "1 Validation accuracy: 0.9114\n",
      "1 Validation accuracy: 0.9118\n",
      "1 Validation accuracy: 0.9124\n",
      "1 Validation accuracy: 0.9134\n",
      "1 Validation accuracy: 0.9138\n",
      "1 Validation accuracy: 0.9116\n",
      "1 Validation accuracy: 0.9132\n",
      "1 Validation accuracy: 0.9138\n",
      "1 Validation accuracy: 0.9142\n",
      "1 Validation accuracy: 0.9122\n",
      "1 Validation accuracy: 0.9124\n",
      "1 Validation accuracy: 0.914\n",
      "1 Validation accuracy: 0.9134\n",
      "1 Validation accuracy: 0.9134\n",
      "1 Validation accuracy: 0.913\n",
      "1 Validation accuracy: 0.9136\n",
      "1 Validation accuracy: 0.9112\n",
      "1 Validation accuracy: 0.9142\n",
      "1 Validation accuracy: 0.915\n",
      "1 Validation accuracy: 0.9142\n",
      "1 Validation accuracy: 0.9144\n",
      "1 Validation accuracy: 0.917\n",
      "1 Validation accuracy: 0.9164\n",
      "1 Validation accuracy: 0.9156\n",
      "1 Validation accuracy: 0.9148\n",
      "1 Validation accuracy: 0.9154\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9172\n",
      "1 Validation accuracy: 0.9152\n",
      "1 Validation accuracy: 0.916\n",
      "1 Validation accuracy: 0.9168\n",
      "1 Validation accuracy: 0.9144\n",
      "1 Validation accuracy: 0.917\n",
      "1 Validation accuracy: 0.9176\n",
      "1 Validation accuracy: 0.9164\n",
      "1 Validation accuracy: 0.9178\n",
      "1 Validation accuracy: 0.9174\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9184\n",
      "1 Validation accuracy: 0.9174\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9172\n",
      "1 Validation accuracy: 0.9168\n",
      "1 Validation accuracy: 0.9168\n",
      "1 Validation accuracy: 0.9148\n",
      "1 Validation accuracy: 0.9148\n",
      "1 Validation accuracy: 0.915\n",
      "1 Validation accuracy: 0.916\n",
      "1 Validation accuracy: 0.917\n",
      "1 Validation accuracy: 0.9172\n",
      "1 Validation accuracy: 0.9176\n",
      "1 Validation accuracy: 0.9136\n",
      "1 Validation accuracy: 0.9164\n",
      "1 Validation accuracy: 0.916\n",
      "1 Validation accuracy: 0.9174\n",
      "1 Validation accuracy: 0.9182\n",
      "1 Validation accuracy: 0.9196\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9172\n",
      "1 Validation accuracy: 0.9154\n",
      "1 Validation accuracy: 0.916\n",
      "1 Validation accuracy: 0.9172\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9182\n",
      "1 Validation accuracy: 0.9178\n",
      "1 Validation accuracy: 0.9186\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9184\n",
      "1 Validation accuracy: 0.9192\n",
      "1 Validation accuracy: 0.9188\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9194\n",
      "1 Validation accuracy: 0.9184\n",
      "1 Validation accuracy: 0.9176\n",
      "1 Validation accuracy: 0.9174\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9196\n",
      "1 Validation accuracy: 0.9206\n",
      "1 Validation accuracy: 0.9196\n",
      "1 Validation accuracy: 0.9194\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9166\n",
      "1 Validation accuracy: 0.9184\n",
      "1 Validation accuracy: 0.9196\n",
      "1 Validation accuracy: 0.9192\n",
      "1 Validation accuracy: 0.919\n",
      "1 Validation accuracy: 0.9196\n",
      "1 Validation accuracy: 0.9208\n",
      "1 Validation accuracy: 0.9212\n",
      "1 Validation accuracy: 0.92\n",
      "1 Validation accuracy: 0.9204\n",
      "1 Validation accuracy: 0.9198\n",
      "1 Validation accuracy: 0.9222\n",
      "1 Validation accuracy: 0.9208\n",
      "1 Validation accuracy: 0.9214\n",
      "1 Validation accuracy: 0.9208\n",
      "1 Validation accuracy: 0.9204\n",
      "1 Validation accuracy: 0.9214\n",
      "1 Validation accuracy: 0.9204\n",
      "1 Validation accuracy: 0.9202\n",
      "1 Validation accuracy: 0.9208\n",
      "1 Validation accuracy: 0.9168\n",
      "1 Validation accuracy: 0.9206\n",
      "1 Validation accuracy: 0.921\n",
      "1 Validation accuracy: 0.9222\n",
      "1 Validation accuracy: 0.9212\n",
      "1 Validation accuracy: 0.9204\n",
      "1 Validation accuracy: 0.9242\n",
      "1 Validation accuracy: 0.9226\n",
      "1 Validation accuracy: 0.9218\n",
      "1 Validation accuracy: 0.9214\n",
      "1 Validation accuracy: 0.9224\n",
      "1 Validation accuracy: 0.9208\n",
      "1 Validation accuracy: 0.9226\n",
      "1 Validation accuracy: 0.9224\n",
      "1 Validation accuracy: 0.9232\n",
      "1 Validation accuracy: 0.9236\n",
      "1 Validation accuracy: 0.9218\n",
      "1 Validation accuracy: 0.9236\n",
      "1 Validation accuracy: 0.9238\n",
      "1 Validation accuracy: 0.9248\n",
      "1 Validation accuracy: 0.9228\n",
      "1 Validation accuracy: 0.924\n",
      "1 Validation accuracy: 0.9204\n",
      "1 Validation accuracy: 0.922\n",
      "1 Validation accuracy: 0.924\n",
      "1 Validation accuracy: 0.9248\n",
      "1 Validation accuracy: 0.9258\n",
      "1 Validation accuracy: 0.924\n",
      "1 Validation accuracy: 0.922\n",
      "1 Validation accuracy: 0.9258\n",
      "1 Validation accuracy: 0.9228\n",
      "1 Validation accuracy: 0.9238\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.9238\n",
      "1 Validation accuracy: 0.925\n",
      "1 Validation accuracy: 0.9238\n",
      "1 Validation accuracy: 0.9246\n",
      "1 Validation accuracy: 0.9246\n",
      "1 Validation accuracy: 0.9232\n",
      "1 Validation accuracy: 0.9226\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.9238\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.924\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9268\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.9244\n",
      "1 Validation accuracy: 0.9228\n",
      "1 Validation accuracy: 0.9244\n",
      "1 Validation accuracy: 0.9244\n",
      "1 Validation accuracy: 0.9246\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9214\n",
      "1 Validation accuracy: 0.9258\n",
      "1 Validation accuracy: 0.9248\n",
      "1 Validation accuracy: 0.9262\n",
      "1 Validation accuracy: 0.9258\n",
      "1 Validation accuracy: 0.9264\n",
      "1 Validation accuracy: 0.9266\n",
      "1 Validation accuracy: 0.9264\n",
      "1 Validation accuracy: 0.9278\n",
      "1 Validation accuracy: 0.9266\n",
      "1 Validation accuracy: 0.9248\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9266\n",
      "1 Validation accuracy: 0.9268\n",
      "1 Validation accuracy: 0.9274\n",
      "1 Validation accuracy: 0.9282\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9226\n",
      "1 Validation accuracy: 0.9252\n",
      "1 Validation accuracy: 0.927\n",
      "1 Validation accuracy: 0.9268\n",
      "1 Validation accuracy: 0.9254\n",
      "1 Validation accuracy: 0.9262\n",
      "1 Validation accuracy: 0.9266\n",
      "1 Validation accuracy: 0.9262\n",
      "1 Validation accuracy: 0.9242\n",
      "1 Validation accuracy: 0.9262\n",
      "1 Validation accuracy: 0.9264\n",
      "1 Validation accuracy: 0.9266\n",
      "1 Validation accuracy: 0.9256\n",
      "1 Validation accuracy: 0.9258\n",
      "1 Validation accuracy: 0.9274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Validation accuracy: 0.9262\n",
      "2 Validation accuracy: 0.9274\n",
      "2 Validation accuracy: 0.9274\n",
      "2 Validation accuracy: 0.9272\n",
      "2 Validation accuracy: 0.928\n",
      "2 Validation accuracy: 0.9278\n",
      "2 Validation accuracy: 0.9282\n",
      "2 Validation accuracy: 0.927\n",
      "2 Validation accuracy: 0.9272\n",
      "2 Validation accuracy: 0.9268\n",
      "2 Validation accuracy: 0.9274\n",
      "2 Validation accuracy: 0.9264\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9298\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9292\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.9298\n",
      "2 Validation accuracy: 0.927\n",
      "2 Validation accuracy: 0.9278\n",
      "2 Validation accuracy: 0.9278\n",
      "2 Validation accuracy: 0.9284\n",
      "2 Validation accuracy: 0.927\n",
      "2 Validation accuracy: 0.9286\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9264\n",
      "2 Validation accuracy: 0.9278\n",
      "2 Validation accuracy: 0.929\n",
      "2 Validation accuracy: 0.9282\n",
      "2 Validation accuracy: 0.9296\n",
      "2 Validation accuracy: 0.9298\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9282\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.929\n",
      "2 Validation accuracy: 0.9278\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9292\n",
      "2 Validation accuracy: 0.9292\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9286\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.931\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9296\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.9288\n",
      "2 Validation accuracy: 0.929\n",
      "2 Validation accuracy: 0.9268\n",
      "2 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.93\n",
      "2 Validation accuracy: 0.933\n",
      "2 Validation accuracy: 0.9322\n",
      "2 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9296\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9296\n",
      "2 Validation accuracy: 0.9294\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9296\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9308\n",
      "2 Validation accuracy: 0.9288\n",
      "2 Validation accuracy: 0.931\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9314\n",
      "2 Validation accuracy: 0.9312\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9302\n",
      "2 Validation accuracy: 0.9324\n",
      "2 Validation accuracy: 0.933\n",
      "2 Validation accuracy: 0.9312\n",
      "2 Validation accuracy: 0.931\n",
      "2 Validation accuracy: 0.9316\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9312\n",
      "2 Validation accuracy: 0.9324\n",
      "2 Validation accuracy: 0.9314\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9336\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9332\n",
      "2 Validation accuracy: 0.933\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9324\n",
      "2 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9322\n",
      "2 Validation accuracy: 0.9322\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9324\n",
      "2 Validation accuracy: 0.9336\n",
      "2 Validation accuracy: 0.9316\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9312\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.9332\n",
      "2 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.933\n",
      "2 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9328\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9328\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9332\n",
      "2 Validation accuracy: 0.9344\n",
      "2 Validation accuracy: 0.9328\n",
      "2 Validation accuracy: 0.9332\n",
      "2 Validation accuracy: 0.9332\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9336\n",
      "2 Validation accuracy: 0.9362\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9342\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9344\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9342\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9326\n",
      "2 Validation accuracy: 0.9342\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.932\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.934\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9358\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.9342\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9368\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.936\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.936\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9366\n",
      "2 Validation accuracy: 0.9364\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9364\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9338\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.935\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9348\n",
      "2 Validation accuracy: 0.9368\n",
      "2 Validation accuracy: 0.9368\n",
      "2 Validation accuracy: 0.9358\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.9346\n",
      "2 Validation accuracy: 0.9362\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9358\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9366\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9368\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9344\n",
      "2 Validation accuracy: 0.9354\n",
      "2 Validation accuracy: 0.9368\n",
      "2 Validation accuracy: 0.9376\n",
      "2 Validation accuracy: 0.9352\n",
      "2 Validation accuracy: 0.9356\n",
      "2 Validation accuracy: 0.9372\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9372\n",
      "2 Validation accuracy: 0.937\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9382\n",
      "2 Validation accuracy: 0.9372\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9374\n",
      "2 Validation accuracy: 0.9366\n",
      "2 Validation accuracy: 0.9374\n",
      "2 Validation accuracy: 0.9372\n",
      "2 Validation accuracy: 0.937\n",
      "2 Validation accuracy: 0.9372\n",
      "2 Validation accuracy: 0.938\n",
      "2 Validation accuracy: 0.9376\n",
      "2 Validation accuracy: 0.9386\n",
      "2 Validation accuracy: 0.938\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9386\n",
      "2 Validation accuracy: 0.9374\n",
      "2 Validation accuracy: 0.9384\n",
      "2 Validation accuracy: 0.9376\n",
      "2 Validation accuracy: 0.937\n",
      "2 Validation accuracy: 0.938\n",
      "2 Validation accuracy: 0.9398\n",
      "2 Validation accuracy: 0.9384\n",
      "2 Validation accuracy: 0.9382\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9374\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.938\n",
      "2 Validation accuracy: 0.9384\n",
      "2 Validation accuracy: 0.9376\n",
      "2 Validation accuracy: 0.9386\n",
      "2 Validation accuracy: 0.9378\n",
      "2 Validation accuracy: 0.9386\n",
      "2 Validation accuracy: 0.937\n",
      "2 Validation accuracy: 0.9376\n",
      "2 Validation accuracy: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9382\n",
      "3 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.936\n",
      "3 Validation accuracy: 0.9378\n",
      "3 Validation accuracy: 0.9376\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.9388\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9382\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.937\n",
      "3 Validation accuracy: 0.9376\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.9388\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.9382\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.9388\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9384\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.937\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9382\n",
      "3 Validation accuracy: 0.9376\n",
      "3 Validation accuracy: 0.938\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9394\n",
      "3 Validation accuracy: 0.9388\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.939\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.9382\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.9394\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.937\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9402\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9392\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.9408\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.9398\n",
      "3 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9406\n",
      "3 Validation accuracy: 0.9434\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9412\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.94\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.941\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9414\n",
      "3 Validation accuracy: 0.9422\n",
      "3 Validation accuracy: 0.9418\n",
      "3 Validation accuracy: 0.9422\n",
      "3 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9434\n",
      "3 Validation accuracy: 0.9396\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9446\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9448\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9454\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9446\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9448\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.9422\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9434\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9454\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9456\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9458\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9436\n",
      "3 Validation accuracy: 0.9446\n",
      "3 Validation accuracy: 0.942\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.9454\n",
      "3 Validation accuracy: 0.9452\n",
      "3 Validation accuracy: 0.9462\n",
      "3 Validation accuracy: 0.9452\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9452\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.943\n",
      "3 Validation accuracy: 0.9424\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9448\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.9452\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9428\n",
      "3 Validation accuracy: 0.9442\n",
      "3 Validation accuracy: 0.9448\n",
      "3 Validation accuracy: 0.9456\n",
      "3 Validation accuracy: 0.9448\n",
      "3 Validation accuracy: 0.9456\n",
      "3 Validation accuracy: 0.9458\n",
      "3 Validation accuracy: 0.9456\n",
      "3 Validation accuracy: 0.9446\n",
      "3 Validation accuracy: 0.9454\n",
      "3 Validation accuracy: 0.944\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.9458\n",
      "3 Validation accuracy: 0.9454\n",
      "3 Validation accuracy: 0.945\n",
      "3 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9444\n",
      "3 Validation accuracy: 0.9456\n",
      "3 Validation accuracy: 0.9444\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9448\n",
      "4 Validation accuracy: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Validation accuracy: 0.9444\n",
      "4 Validation accuracy: 0.9446\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.9436\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.945\n",
      "4 Validation accuracy: 0.944\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9438\n",
      "4 Validation accuracy: 0.944\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9448\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9448\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9448\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9446\n",
      "4 Validation accuracy: 0.943\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9418\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9432\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.945\n",
      "4 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.9446\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.944\n",
      "4 Validation accuracy: 0.9446\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9434\n",
      "4 Validation accuracy: 0.9446\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9458\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.948\n",
      "4 Validation accuracy: 0.9452\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9448\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.946\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9456\n",
      "4 Validation accuracy: 0.9454\n",
      "4 Validation accuracy: 0.9444\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.9464\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9482\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.948\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9482\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.948\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9492\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9462\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9466\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.947\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9482\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9504\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9504\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9508\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9482\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9474\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9492\n",
      "4 Validation accuracy: 0.9512\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9492\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.948\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.9484\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.95\n",
      "4 Validation accuracy: 0.9504\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.949\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9482\n",
      "4 Validation accuracy: 0.9498\n",
      "4 Validation accuracy: 0.9506\n",
      "4 Validation accuracy: 0.9504\n",
      "4 Validation accuracy: 0.9502\n",
      "4 Validation accuracy: 0.9496\n",
      "4 Validation accuracy: 0.9478\n",
      "4 Validation accuracy: 0.9488\n",
      "4 Validation accuracy: 0.9504\n",
      "4 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.949\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9492\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9494\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9482\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9482\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9492\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9494\n",
      "5 Validation accuracy: 0.9486\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9486\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.949\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9494\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9502\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.95\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9498\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9496\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9504\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9512\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9506\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9536\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.954\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9536\n",
      "5 Validation accuracy: 0.9544\n",
      "5 Validation accuracy: 0.954\n",
      "5 Validation accuracy: 0.9542\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9548\n",
      "5 Validation accuracy: 0.9544\n",
      "5 Validation accuracy: 0.9546\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9538\n",
      "5 Validation accuracy: 0.9532\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9548\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9536\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9538\n",
      "5 Validation accuracy: 0.9542\n",
      "5 Validation accuracy: 0.9534\n",
      "5 Validation accuracy: 0.954\n",
      "5 Validation accuracy: 0.9544\n",
      "5 Validation accuracy: 0.9538\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9516\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9536\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.952\n",
      "5 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9518\n",
      "5 Validation accuracy: 0.9508\n",
      "5 Validation accuracy: 0.9488\n",
      "5 Validation accuracy: 0.9526\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9528\n",
      "5 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.953\n",
      "5 Validation accuracy: 0.9524\n",
      "5 Validation accuracy: 0.9538\n",
      "5 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.952\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.952\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.9518\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9524\n",
      "6 Validation accuracy: 0.9524\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9516\n",
      "6 Validation accuracy: 0.9514\n",
      "6 Validation accuracy: 0.952\n",
      "6 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.9524\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.952\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9556\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9556\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9556\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9536\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9538\n",
      "6 Validation accuracy: 0.9548\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9526\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.955\n",
      "6 Validation accuracy: 0.9542\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9544\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9566\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.9576\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9534\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9566\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.957\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9546\n",
      "6 Validation accuracy: 0.9556\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9572\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.957\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9552\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9554\n",
      "6 Validation accuracy: 0.9528\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9566\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9572\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9564\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.957\n",
      "6 Validation accuracy: 0.9576\n",
      "6 Validation accuracy: 0.9568\n",
      "6 Validation accuracy: 0.9584\n",
      "6 Validation accuracy: 0.9558\n",
      "6 Validation accuracy: 0.9562\n",
      "6 Validation accuracy: 0.9566\n",
      "6 Validation accuracy: 0.9576\n",
      "6 Validation accuracy: 0.9582\n",
      "6 Validation accuracy: 0.958\n",
      "6 Validation accuracy: 0.9582\n",
      "6 Validation accuracy: 0.9574\n",
      "6 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9562\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.954\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9552\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9548\n",
      "7 Validation accuracy: 0.9542\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9536\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9538\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9552\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9562\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.955\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9562\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9562\n",
      "7 Validation accuracy: 0.9562\n",
      "7 Validation accuracy: 0.9558\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9554\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9592\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9566\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9564\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.96\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.96\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.96\n",
      "7 Validation accuracy: 0.9592\n",
      "7 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.9602\n",
      "7 Validation accuracy: 0.96\n",
      "7 Validation accuracy: 0.9602\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9596\n",
      "7 Validation accuracy: 0.9602\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9592\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.959\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.959\n",
      "7 Validation accuracy: 0.9602\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9572\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.959\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.959\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9584\n",
      "7 Validation accuracy: 0.9586\n",
      "7 Validation accuracy: 0.9594\n",
      "7 Validation accuracy: 0.9574\n",
      "7 Validation accuracy: 0.9592\n",
      "7 Validation accuracy: 0.9588\n",
      "7 Validation accuracy: 0.957\n",
      "7 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.958\n",
      "7 Validation accuracy: 0.9578\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9582\n",
      "7 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9564\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.957\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9568\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.958\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9576\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.961\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.957\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.958\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.958\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9576\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.958\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9562\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.956\n",
      "8 Validation accuracy: 0.957\n",
      "8 Validation accuracy: 0.9562\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.957\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.956\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9576\n",
      "8 Validation accuracy: 0.9576\n",
      "8 Validation accuracy: 0.9568\n",
      "8 Validation accuracy: 0.9578\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9566\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9612\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9614\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9582\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9572\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9574\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9594\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9574\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9588\n",
      "8 Validation accuracy: 0.9618\n",
      "8 Validation accuracy: 0.9616\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.9602\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9584\n",
      "8 Validation accuracy: 0.9586\n",
      "8 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.961\n",
      "8 Validation accuracy: 0.9598\n",
      "8 Validation accuracy: 0.9574\n",
      "8 Validation accuracy: 0.9604\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9592\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.961\n",
      "8 Validation accuracy: 0.9618\n",
      "8 Validation accuracy: 0.9596\n",
      "8 Validation accuracy: 0.9606\n",
      "8 Validation accuracy: 0.9608\n",
      "8 Validation accuracy: 0.958\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9586\n",
      "9 Validation accuracy: 0.9574\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9574\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9586\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9622\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9622\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9584\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9582\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9604\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9596\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.96\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9598\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9602\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9616\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.961\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9622\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9634\n",
      "9 Validation accuracy: 0.963\n",
      "9 Validation accuracy: 0.9638\n",
      "9 Validation accuracy: 0.9594\n",
      "9 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9636\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.963\n",
      "9 Validation accuracy: 0.9618\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9624\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9592\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9606\n",
      "9 Validation accuracy: 0.9608\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9614\n",
      "9 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9602\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9574\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9592\n",
      "10 Validation accuracy: 0.9604\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9596\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9602\n",
      "10 Validation accuracy: 0.9602\n",
      "10 Validation accuracy: 0.9596\n",
      "10 Validation accuracy: 0.9594\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9598\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9604\n",
      "10 Validation accuracy: 0.9604\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9602\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.959\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9604\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9598\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.964\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.96\n",
      "10 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9606\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.961\n",
      "10 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9652\n",
      "10 Validation accuracy: 0.9636\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9614\n",
      "10 Validation accuracy: 0.9632\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.964\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.962\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9634\n",
      "10 Validation accuracy: 0.9628\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.963\n",
      "10 Validation accuracy: 0.9594\n",
      "10 Validation accuracy: 0.9596\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9624\n",
      "10 Validation accuracy: 0.9626\n",
      "10 Validation accuracy: 0.9612\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9618\n",
      "10 Validation accuracy: 0.9622\n",
      "10 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.96\n",
      "11 Validation accuracy: 0.9614\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.961\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9614\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.96\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9614\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9608\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.96\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9604\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9608\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9644\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.961\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.961\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9614\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9598\n",
      "11 Validation accuracy: 0.9604\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9622\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9606\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.961\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9652\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9654\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9644\n",
      "11 Validation accuracy: 0.966\n",
      "11 Validation accuracy: 0.9664\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9624\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9632\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9608\n",
      "11 Validation accuracy: 0.9618\n",
      "11 Validation accuracy: 0.9612\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9626\n",
      "11 Validation accuracy: 0.9634\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9658\n",
      "11 Validation accuracy: 0.9652\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9656\n",
      "11 Validation accuracy: 0.9654\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9658\n",
      "11 Validation accuracy: 0.9648\n",
      "11 Validation accuracy: 0.9636\n",
      "11 Validation accuracy: 0.9658\n",
      "11 Validation accuracy: 0.966\n",
      "11 Validation accuracy: 0.9654\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.9656\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9654\n",
      "11 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.964\n",
      "11 Validation accuracy: 0.966\n",
      "11 Validation accuracy: 0.9616\n",
      "11 Validation accuracy: 0.963\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9646\n",
      "11 Validation accuracy: 0.9656\n",
      "11 Validation accuracy: 0.9642\n",
      "11 Validation accuracy: 0.9652\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9644\n",
      "11 Validation accuracy: 0.9638\n",
      "11 Validation accuracy: 0.9644\n",
      "11 Validation accuracy: 0.9628\n",
      "11 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.962\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9626\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.962\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9622\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9628\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9618\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9622\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9628\n",
      "12 Validation accuracy: 0.9626\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9622\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9664\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.9664\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9628\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9626\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9628\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.9618\n",
      "12 Validation accuracy: 0.967\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.963\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9624\n",
      "12 Validation accuracy: 0.9626\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9632\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9634\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9638\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9664\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9656\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9646\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9626\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9666\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9674\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9658\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9652\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.965\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9648\n",
      "12 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9642\n",
      "12 Validation accuracy: 0.9662\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.9644\n",
      "12 Validation accuracy: 0.9654\n",
      "12 Validation accuracy: 0.964\n",
      "12 Validation accuracy: 0.9618\n",
      "12 Validation accuracy: 0.9602\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.962\n",
      "13 Validation accuracy: 0.9612\n",
      "13 Validation accuracy: 0.9634\n",
      "13 Validation accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Validation accuracy: 0.9636\n",
      "13 Validation accuracy: 0.9634\n",
      "13 Validation accuracy: 0.9618\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.964\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.964\n",
      "13 Validation accuracy: 0.9636\n",
      "13 Validation accuracy: 0.9626\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.964\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.963\n",
      "13 Validation accuracy: 0.9618\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9622\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9636\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9626\n",
      "13 Validation accuracy: 0.9628\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9636\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.963\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.968\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9628\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9624\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.963\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9632\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.964\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9646\n",
      "13 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.9636\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9622\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9656\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9668\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.9666\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9662\n",
      "13 Validation accuracy: 0.9678\n",
      "13 Validation accuracy: 0.9676\n",
      "13 Validation accuracy: 0.9678\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9628\n",
      "13 Validation accuracy: 0.9634\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9628\n",
      "13 Validation accuracy: 0.963\n",
      "13 Validation accuracy: 0.9648\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9652\n",
      "13 Validation accuracy: 0.9644\n",
      "13 Validation accuracy: 0.9654\n",
      "13 Validation accuracy: 0.9674\n",
      "13 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.967\n",
      "13 Validation accuracy: 0.966\n",
      "13 Validation accuracy: 0.9676\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9658\n",
      "13 Validation accuracy: 0.9674\n",
      "13 Validation accuracy: 0.9664\n",
      "13 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9686\n",
      "14 Validation accuracy: 0.968\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.964\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9632\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9642\n",
      "14 Validation accuracy: 0.9636\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9636\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9638\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9632\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9642\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9636\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9678\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.964\n",
      "14 Validation accuracy: 0.9638\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9642\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9638\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.964\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9644\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9644\n",
      "14 Validation accuracy: 0.9622\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9644\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9642\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9644\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9634\n",
      "14 Validation accuracy: 0.9626\n",
      "14 Validation accuracy: 0.964\n",
      "14 Validation accuracy: 0.9644\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.965\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9654\n",
      "14 Validation accuracy: 0.9646\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9656\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.964\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9668\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9658\n",
      "14 Validation accuracy: 0.9648\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.968\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9652\n",
      "14 Validation accuracy: 0.968\n",
      "14 Validation accuracy: 0.9664\n",
      "14 Validation accuracy: 0.9662\n",
      "14 Validation accuracy: 0.968\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9684\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.9684\n",
      "14 Validation accuracy: 0.9682\n",
      "14 Validation accuracy: 0.968\n",
      "14 Validation accuracy: 0.9676\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Validation accuracy: 0.9688\n",
      "14 Validation accuracy: 0.9678\n",
      "14 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9686\n",
      "14 Validation accuracy: 0.9672\n",
      "14 Validation accuracy: 0.9674\n",
      "14 Validation accuracy: 0.9666\n",
      "14 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9644\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9648\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9642\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9686\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9646\n",
      "15 Validation accuracy: 0.9646\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.965\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9668\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9644\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.965\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9688\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.969\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9686\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9654\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.9678\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9628\n",
      "15 Validation accuracy: 0.9626\n",
      "15 Validation accuracy: 0.9622\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9682\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.968\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9674\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.965\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.967\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.964\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.965\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.9662\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.9668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9686\n",
      "15 Validation accuracy: 0.9686\n",
      "15 Validation accuracy: 0.9676\n",
      "15 Validation accuracy: 0.9658\n",
      "15 Validation accuracy: 0.9656\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9666\n",
      "15 Validation accuracy: 0.9652\n",
      "15 Validation accuracy: 0.9672\n",
      "15 Validation accuracy: 0.966\n",
      "15 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9652\n",
      "16 Validation accuracy: 0.9642\n",
      "16 Validation accuracy: 0.964\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9642\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9654\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9644\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.969\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9648\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9652\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9646\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9652\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.969\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.965\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9646\n",
      "16 Validation accuracy: 0.9652\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9654\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9692\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9686\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.965\n",
      "16 Validation accuracy: 0.9648\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9688\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9684\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9666\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9656\n",
      "16 Validation accuracy: 0.9668\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9676\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9674\n",
      "16 Validation accuracy: 0.9678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.968\n",
      "16 Validation accuracy: 0.967\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9642\n",
      "16 Validation accuracy: 0.9648\n",
      "16 Validation accuracy: 0.9644\n",
      "16 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.9664\n",
      "16 Validation accuracy: 0.9672\n",
      "16 Validation accuracy: 0.9662\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9678\n",
      "16 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9646\n",
      "17 Validation accuracy: 0.965\n",
      "17 Validation accuracy: 0.9642\n",
      "17 Validation accuracy: 0.965\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9696\n",
      "17 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.965\n",
      "17 Validation accuracy: 0.965\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9652\n",
      "17 Validation accuracy: 0.9654\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9646\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9652\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.97\n",
      "17 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9656\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.9668\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.9662\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9656\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9666\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.966\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.9674\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9696\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9686\n",
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9664\n",
      "17 Validation accuracy: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.968\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.965\n",
      "17 Validation accuracy: 0.9684\n",
      "17 Validation accuracy: 0.969\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9692\n",
      "17 Validation accuracy: 0.97\n",
      "17 Validation accuracy: 0.9658\n",
      "17 Validation accuracy: 0.9694\n",
      "17 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9698\n",
      "17 Validation accuracy: 0.9688\n",
      "17 Validation accuracy: 0.9682\n",
      "17 Validation accuracy: 0.9694\n",
      "17 Validation accuracy: 0.9696\n",
      "17 Validation accuracy: 0.9672\n",
      "17 Validation accuracy: 0.9676\n",
      "17 Validation accuracy: 0.9678\n",
      "17 Validation accuracy: 0.9652\n",
      "17 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9698\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9698\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9694\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9656\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9662\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.97\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9642\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9662\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9656\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9696\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9644\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9652\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9662\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.9662\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9702\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9658\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9658\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9654\n",
      "18 Validation accuracy: 0.9664\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9698\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9706\n",
      "18 Validation accuracy: 0.9694\n",
      "18 Validation accuracy: 0.9658\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9696\n",
      "18 Validation accuracy: 0.9694\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.967\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9662\n",
      "18 Validation accuracy: 0.9666\n",
      "18 Validation accuracy: 0.9648\n",
      "18 Validation accuracy: 0.9668\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9678\n",
      "18 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9656\n",
      "18 Validation accuracy: 0.9696\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.9692\n",
      "18 Validation accuracy: 0.9686\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9684\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9688\n",
      "18 Validation accuracy: 0.9704\n",
      "18 Validation accuracy: 0.9694\n",
      "18 Validation accuracy: 0.97\n",
      "18 Validation accuracy: 0.9698\n",
      "18 Validation accuracy: 0.966\n",
      "18 Validation accuracy: 0.9672\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.969\n",
      "18 Validation accuracy: 0.9682\n",
      "18 Validation accuracy: 0.968\n",
      "18 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9656\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9704\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9708\n",
      "19 Validation accuracy: 0.971\n",
      "19 Validation accuracy: 0.9706\n",
      "19 Validation accuracy: 0.9704\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.966\n",
      "19 Validation accuracy: 0.9656\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9656\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9652\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.966\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9652\n",
      "19 Validation accuracy: 0.9654\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.971\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9644\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9656\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.968\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9674\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9708\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9704\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9664\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9704\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.967\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9676\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9672\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.9706\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.969\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9702\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.97\n",
      "19 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9696\n",
      "19 Validation accuracy: 0.9692\n",
      "19 Validation accuracy: 0.9682\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9686\n",
      "19 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9668\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9678\n",
      "19 Validation accuracy: 0.9688\n",
      "19 Validation accuracy: 0.9698\n",
      "19 Validation accuracy: 0.9686\n"
     ]
    }
   ],
   "source": [
    "# Now we can train this new model:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y: y_batch})\n",
    "            accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "            \n",
    "        save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have access to the Python code that built the original graph, you can just reuse the parts you need and drop the rest:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50 # reused\n",
    "n_hidden3 = 50 # reused\n",
    "n_hidden4 = 20 # new\n",
    "n_outputs = 10 # new\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y= tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\") # Reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name= \"hidden2\") # Reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name= \"hidden3\") # Reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name= \"hidden4\") #New\n",
    "    logits = tf.layers.dense(hidden4, n_outputs,name= \"outputs\") # New\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9\n",
      "1 Validation accuracy: 0.9318\n",
      "2 Validation accuracy: 0.9416\n",
      "3 Validation accuracy: 0.9468\n",
      "4 Validation accuracy: 0.9494\n",
      "5 Validation accuracy: 0.953\n",
      "6 Validation accuracy: 0.956\n",
      "7 Validation accuracy: 0.9568\n",
      "8 Validation accuracy: 0.959\n",
      "9 Validation accuracy: 0.9616\n",
      "10 Validation accuracy: 0.9602\n",
      "11 Validation accuracy: 0.9636\n",
      "12 Validation accuracy: 0.965\n",
      "13 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9646\n",
      "15 Validation accuracy: 0.966\n",
      "16 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9676\n",
      "18 Validation accuracy: 0.9662\n",
      "19 Validation accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# However, you must create one Saver to restore the pretrained model (giving it the list of variables to restore, or else it will complain that the graphs don't match), and another Saver to save the new model, once it is trained:\n",
    "# The following code restores only hidden layers 1, 2, and 3:\n",
    "\n",
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden[123]\") # regular expression\n",
    "\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch,y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In summary, first we build the new model, making sure to copy the original model's hidden layers 1 to 3.\n",
    "# Then we get the list of all variables in hidden layers 1 to 3, using the regular expression \"hidden[123]\".\n",
    "# Next we create a dictionary that maps the name of each variable in the original model to its name in the new model(generally you want to keep the exact same names).\n",
    "# Then we create a Saver that will restore only these variables.\n",
    "# We also create an operation to initialize all the variables(old and new) and a second Saver to save the entire new model, not just layers 1-3.\n",
    "# We then start a session and initialize all variables in the model, then restore the variable values from the original model's layers 1-3.\n",
    "# Finally, we train the model on the new task and save it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing Models from Other Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model was trained using another framework, you will need to load the model parameters manually, then assign them to appropriate variables.\n",
    "# This can be quite tedious. The following code shows how you would copy the weight and biases from the first hidden layer of a model trained using a different framework.\n",
    "\n",
    "# In this example, for each variable we want to reuse, we will findits initializer's assignment operation, and we get its second input, which corresponds to the initialization value.\n",
    "# When we run the initializer, we replace the initialization values with the ones we want, using feed_dict:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights and biases from the other framework.\n",
    "original_b = [7., 8., 9.] # Load the weights and biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the assignment nodes for the hidden1 variables\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above implementation, we first load the pretrained model using the other framework.\n",
    "# Then we extract from it model parameters we wanr to reuse. \n",
    "# Then we build our Tensorflow Model as usual.\n",
    "# The tricky part is that every Tensorflow Variable has an associated assignment operation that is used to intialize it.\n",
    "# We start by getting a handle on these assignment operations. We also get a handle on each assignment's handle input.\n",
    "# Blah.... Blah.... Blah... Read page 294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "# Note that for the previous code, the weights variable created by the tf.layers.dense() function is called \"kernel\" instead of \"weights\", when using the tf.contrib.layers.fully_connected().\n",
    "# Also the biases variable is called bias instead of biases/\n",
    "\n",
    "# Another approach (initially used in the book) would be to create dedicated assignment nodes and dedicated placeholders. This is more verbose and less efficient, but you may find this method more explicit:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.] # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the variables of layer_hidden1\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True): # root scope\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "    \n",
    "# Create dedicated placeholders and assignment nodes\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases =tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    \n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that we could also get a handle on the variables using get_collection() and specifying the scope:\n",
    "\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we could use the graph's get_tensor_by_name() method:\n",
    "\n",
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing the Lower Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the old image classification network to work with in this section\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is likely that the lower layers of the first DNN have learned to detect low-level features in pictures that will be useful across both image classification tasks, so you can just reuse these layers as they are.\n",
    "# It is generally a good idea to \"freeze\" their weights when training the new DNN: if the lower layers are frozen, it will be easier to train the higher level layers.\n",
    "\n",
    "# To freeze the lower layers during training, one solution is to give the optimizer the list of variables to train, excluding variables from the lower layers:\n",
    "\n",
    "with tf.name_scope(\"train\"): # Not shown in the book.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate) # Not shown in the book.\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)\n",
    "    \n",
    "    # train_vars gets the list of all trainable variables in hidden layers 3 & 4 and the output layer. This leaves out hidden layers 1 and 2.\n",
    "    # Next we provide this restricted list of trainable variables to the optimizer's minimize( function().\n",
    "    # Now Layers 1 & 2 are frozen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching the Frozen Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the frozen layers won't change, it is possible to cache the output of the topmost frozen layer for each training instance.\n",
    "# Since training goes throug the dataset many times, this will provide a huge speed boost as you will only need to go through the frozen layers once per training instance (Instead of once per epoch).\n",
    "\n",
    "# First let's create the first Deep Neural Network for MNIST:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50 # reused\n",
    "n_hidden3 = 50 # reused\n",
    "n_hidden4 = 20 # new!\n",
    "n_outputs = 10 # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\") # Reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused frozen and cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9004\n",
      "1 Validation accuracy: 0.9328\n",
      "2 Validation accuracy: 0.9438\n",
      "3 Validation accuracy: 0.9486\n",
      "4 Validation accuracy: 0.951\n",
      "5 Validation accuracy: 0.9516\n",
      "6 Validation accuracy: 0.9532\n",
      "7 Validation accuracy: 0.9546\n",
      "8 Validation accuracy: 0.9548\n",
      "9 Validation accuracy: 0.9556\n",
      "10 Validation accuracy: 0.9566\n",
      "11 Validation accuracy: 0.9566\n",
      "12 Validation accuracy: 0.9574\n",
      "13 Validation accuracy: 0.957\n",
      "14 Validation accuracy: 0.958\n",
      "15 Validation accuracy: 0.9574\n",
      "16 Validation accuracy: 0.9588\n",
      "17 Validation accuracy: 0.9578\n",
      "18 Validation accuracy: 0.9584\n",
      "19 Validation accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "# We can run the whole training set through the lower layers, then during training, instead of building batches of training instances, you would build batches of outputs from hidden layer 2 and feed them to the training op:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # Not shown in the book\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "            \n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, y: y_valid})\n",
    "        \n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")\n",
    "    \n",
    "# The last line of the training loop runs the training operation defined earlier, and feeds it a batch of outputs from the second hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a very large deep neural network can be painfully slow.\n",
    "# So far we've seen four ways to speed up training:\n",
    "    # Applying a good initialization strategy for the connection wieghts.\n",
    "    # Using Batch Normalization\n",
    "    # Reusing Parts of a pretrained network.\n",
    "\n",
    "# Another huge speed boost comes from using a faster optimizer than the regular Gradient Descent optimizer.\n",
    "# In this section we will present the most popular ones: \n",
    "    # Momentum Optimization\n",
    "    # Nesterov Accelerated Gradient\n",
    "    # AdaGrad\n",
    "    # RMSProp\n",
    "    # Adam Optimization\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent will take small regular steps down the slope.\n",
    "# Momentum Optimization will start out slowly, but will pick up momentum until it reaches terminal velocity.\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov Accelerated Gradient is a small variant of Momentum Optimization.\n",
    "# The idea is to measure the gradient of the cost function, not at the local position slightly ahead in the direction of the momentum.\n",
    "# This small tweak works because in general the momentum vector will be pointing in the right direction, so it will be slightly more accurate to use the gradient measured a bit further in that direction, rather then using the gradient at the original position.\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the elongated bowl problem again: Gradient Descent starts quickly going down the steepest slope, then slowly down the bottom of the valley.\n",
    "# It would be nice if the algorithm could detect this early on and correct its direction to point a bit more toward the global optimum.\n",
    "# The AdaGrad Algorithm achieves this by scaling down the gradient vector along the steepest dimensions.\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although AdaGrad slows down a bit too fast and ends up never converging to the global optimum...\n",
    "# The RMSProp algorithm fixes this by accumulating only the gradients from the most recent iterations(as opposed to all the gradients since the beginning of training).\n",
    "# It does so using exponential decay in the first step.\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate, momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam stands for Adaptive Moment Estimation. It combines the ideas of Momentum optimization and RMSProp:\n",
    "    # Just like Momentum Optimization it keeps track of an exponentially decaying average of past gradients\n",
    "    # Just like RMSProp it keeps track of an exponentially decaying average of past SQUARED gradients.\n",
    "    \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "# Since the Adam Optimizer is an adaptive learning rate algorithm, it requires less tuning of the learning rate  hyperparameter.\n",
    "# We can often use the default hyperparameter value of .001, making Adam even easier to use than GradientDescent` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a good learning rate can be tricky.\n",
    "    # If you set it too high, training might actually diverge.\n",
    "    # If you set it too low, training will eventually converge to the optimum, but it will take a very long time.\n",
    "    \n",
    "# In order to get around this issue, we can avoid using a constant learning rate: start with a high learning rate and then reduce it once it stops making fast progress.\n",
    "    # There are many techniques to implement this non-constant learning rate. They are called learning schedules.\n",
    "    # The most common learning schedule techniques are:\n",
    "        # Predetermined piecewise constant learning rate\n",
    "        # Performance Scheduling\n",
    "        # Exponential Scheduling\n",
    "        # Power Scheduling\n",
    "\n",
    "# Implementing a learning schedule with tensorflow is relatively straightforward.\n",
    "# First, let's create a NN Model:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Code below implements the Learning Rate Scheduling Algorithm  as well as training optimizer:\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step, decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9656\n",
      "1 Validation accuracy: 0.9736\n",
      "2 Validation accuracy: 0.9728\n",
      "3 Validation accuracy: 0.9818\n",
      "4 Validation accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Networks typically have tens of thousands of parameters, sometimes millions.\n",
    "# With so many parameters, the network has an incredible amount of freedom and can fit a huge variety of complex datasets.\n",
    "# But this great flexibility can lead to overfitting datasets.\n",
    "# Therefore, we need to Regularize the Network using some of these techniques in TensorFlow:\n",
    "    # Early Stopping\n",
    "    # l1 and l2 regularization\n",
    "    # Dropout\n",
    "    # Max-norm regularization\n",
    "    # Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping is to just interrupt training when its performance  on the validation set starts dropping.\n",
    "# In Tensorflow, a method is to evaluate the model on a validation set at regular intervals, and save a \"winner\" snapshot if it outperforms previous winners.\n",
    "# Count the number of steps since the last \"winner\" snapshot was saved, and interrupt training when this number reaches some limit.\n",
    "# Then restore the last \"Winner\" snapshot.\n",
    "\n",
    "# Although early stopping works well in practice, you can usually get much higher performance out of your network by combining it with other regularization techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# l1 and l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a technique just like in Chapter 4, where you constrain a neural network's connection weights.\n",
    "# In TensorFlow, one way to do this is to add the appropriate regularization terms to your cost function.\n",
    "\n",
    "# For example, assuming you have just one hidden layer (for simplicity) with weights W1 and one output layer with weights W2, then you apply l1 regularization like this:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we get a handle on the layer weights, and we compute the total loss, which is equal to the sum of the usual cross entropy loss and the l1 loss(i.e, the absolute values of the weights):\n",
    "\n",
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel: 0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel: 0\")\n",
    "\n",
    "scale = 0.001 #l1 regularization hyperparameter\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is just as usual:\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.831\n",
      "1 Validation accuracy: 0.871\n",
      "2 Validation accuracy: 0.8838\n",
      "3 Validation accuracy: 0.8934\n",
      "4 Validation accuracy: 0.8966\n",
      "5 Validation accuracy: 0.8988\n",
      "6 Validation accuracy: 0.9016\n",
      "7 Validation accuracy: 0.9044\n",
      "8 Validation accuracy: 0.9058\n",
      "9 Validation accuracy: 0.906\n",
      "10 Validation accuracy: 0.9068\n",
      "11 Validation accuracy: 0.9054\n",
      "12 Validation accuracy: 0.907\n",
      "13 Validation accuracy: 0.9084\n",
      "14 Validation accuracy: 0.9088\n",
      "15 Validation accuracy: 0.9064\n",
      "16 Validation accuracy: 0.9068\n",
      "17 Validation accuracy: 0.9066\n",
      "18 Validation accuracy: 0.9066\n",
      "19 Validation accuracy: 0.9052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can pass a regularization function to the tf.layers.dense() function, which will use it to create operations that will compute the regularization loss, and it adds these operations to the collection of regularization losses.\n",
    "# The beginning is the same as above:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will use Python's partial() function to avoid repeating the same arguments over and over again. \n",
    "# Note that we set the kernel_regularizer argument:\n",
    "\n",
    "scale = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we must add the regularization losses to the base loss:\n",
    "\n",
    "with tf.name_scope(\"loss\"): # not shown in the book\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the rest is the same as usual:\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.7798\n",
      "1 Validation accuracy: 0.7804\n",
      "2 Validation accuracy: 0.6812\n",
      "3 Validation accuracy: 0.5668\n",
      "4 Validation accuracy: 0.5456\n",
      "5 Validation accuracy: 0.5728\n",
      "6 Validation accuracy: 0.6352\n",
      "7 Validation accuracy: 0.6708\n",
      "8 Validation accuracy: 0.6948\n",
      "9 Validation accuracy: 0.7138\n",
      "10 Validation accuracy: 0.7272\n",
      "11 Validation accuracy: 0.7392\n",
      "12 Validation accuracy: 0.7508\n",
      "13 Validation accuracy: 0.7606\n",
      "14 Validation accuracy: 0.7662\n",
      "15 Validation accuracy: 0.771\n",
      "16 Validation accuracy: 0.7792\n",
      "17 Validation accuracy: 0.7854\n",
      "18 Validation accuracy: 0.7876\n",
      "19 Validation accuracy: 0.7942\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/my_model_final.ckpt.data-00000-of-00001.tempstate5434930490947277620; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, hidden1/bias, hidden1/kernel, hidden2/bias, hidden2/kernel, outputs/bias, outputs/kernel)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-160-a353622630da>\", line 14, in <module>\n    saver = tf.train.Saver()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nPermissionDeniedError (see above for traceback): /my_model_final.ckpt.data-00000-of-00001.tempstate5434930490947277620; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, hidden1/bias, hidden1/kernel, hidden2/bias, hidden2/kernel, outputs/bias, outputs/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /my_model_final.ckpt.data-00000-of-00001.tempstate5434930490947277620; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, hidden1/bias, hidden1/kernel, hidden2/bias, hidden2/kernel, outputs/bias, outputs/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-323da7af2722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Validation accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/my_model_final.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1571\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1572\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /my_model_final.ckpt.data-00000-of-00001.tempstate5434930490947277620; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, hidden1/bias, hidden1/kernel, hidden2/bias, hidden2/kernel, outputs/bias, outputs/kernel)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-160-a353622630da>\", line 14, in <module>\n    saver = tf.train.Saver()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 748, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 296, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 239, in save_op\n    tensors)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1163, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/lam/ml/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nPermissionDeniedError (see above for traceback): /my_model_final.ckpt.data-00000-of-00001.tempstate5434930490947277620; Permission denied\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, hidden1/bias, hidden1/kernel, hidden2/bias, hidden2/kernel, outputs/bias, outputs/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the most popular regularization technique for deep neural networks. Even state of the art NN got a 1-2% accuracy boost simply by adding dropout.\n",
    "# Tha algorithm is fairly simple: at every training step, every neuron (including the input neurons but excluding the output neurons) has a probability p of being temporarily \"dropped out\"\n",
    "# Being \"dropped out\" means the Neuron will be entirely ignored during the next step.\n",
    "# The hyperparameter p is called the dropout rate, and is typically set to %50.\n",
    "# After training, neurons don't get dropped anymore.\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To implement dropout in TensorFlow,we use tf.layers.dropout():\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5 # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss =tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9254\n",
      "1 Validation accuracy: 0.9452\n",
      "2 Validation accuracy: 0.9492\n",
      "3 Validation accuracy: 0.9566\n",
      "4 Validation accuracy: 0.9618\n",
      "5 Validation accuracy: 0.9608\n",
      "6 Validation accuracy: 0.9598\n",
      "7 Validation accuracy: 0.9674\n",
      "8 Validation accuracy: 0.9698\n",
      "9 Validation accuracy: 0.9714\n",
      "10 Validation accuracy: 0.969\n",
      "11 Validation accuracy: 0.9674\n",
      "12 Validation accuracy: 0.971\n",
      "13 Validation accuracy: 0.97\n",
      "14 Validation accuracy: 0.9722\n",
      "15 Validation accuracy: 0.9698\n",
      "16 Validation accuracy: 0.973\n",
      "17 Validation accuracy: 0.9724\n",
      "18 Validation accuracy: 0.973\n",
      "19 Validation accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Norm Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each neuron, it constrains the weights w of the incoming connectionssuch that the absolute value of w is less then r.\n",
    "# r is the max-norm hyperparameter. Reducing r increases the amount of regularization and helps reduce overfitting.\n",
    "# Max-norm regularization can also help alleviate the vanishing/exploding gradients problems(if you aren't using Batch Normalization).\n",
    "# TensorFlow doesn't provide an off-the-shelf max-norm regularizer, but its not too hard to regularize:\n",
    "# The following code gets a handle on the weights of the first hidden layer, then uses the clip_by_norm() function to create an operation that will clip the weights along the second axis so that each row vector ends up with a maximum norm of 1.0.\n",
    "\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's get a handle on the first hidden layer's weight and create an operation that will compute the clipped weights using the clip_by_norm() function.\n",
    "# Then we create an assignment operation to asign the clipped weights to the weights variable:\n",
    "\n",
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do this as well for the second hidden layer:\n",
    "\n",
    "weights2 = tf.get_default_graph(). get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add an initializer and a saver:\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we can train the model. It's pretty much as usual, except that right after running the training_op, we run the clip_weights2 operations:\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9566\n",
      "1 Validation accuracy: 0.9706\n",
      "2 Validation accuracy: 0.9724\n",
      "3 Validation accuracy: 0.9762\n",
      "4 Validation accuracy: 0.9762\n",
      "5 Validation accuracy: 0.9768\n",
      "6 Validation accuracy: 0.9808\n",
      "7 Validation accuracy: 0.9818\n",
      "8 Validation accuracy: 0.9806\n",
      "9 Validation accuracy: 0.9816\n",
      "10 Validation accuracy: 0.982\n",
      "11 Validation accuracy: 0.9838\n",
      "12 Validation accuracy: 0.9816\n",
      "13 Validation accuracy: 0.9838\n",
      "14 Validation accuracy: 0.9844\n",
      "15 Validation accuracy: 0.9842\n",
      "16 Validation accuracy: 0.9834\n",
      "17 Validation accuracy: 0.9838\n",
      "18 Validation accuracy: 0.9838\n",
      "19 Validation accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()\n",
    "            \n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implementation above is straightforward and works fine, but it is a bit messy. \n",
    "# A better approach is to define a max_norm_regularizer() function:\n",
    "\n",
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\", collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then you can call this function to get a max norm regularizer(with the threshold you want).\n",
    "# When you create a hiden layer, you can pass this regularizer to the kernel_regularizer argument:\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training is as usual, except you must run the weights clipping operations after each training operation:\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation Accuracy: 0.9588\n",
      "1 Validation Accuracy: 0.9716\n",
      "2 Validation Accuracy: 0.97\n",
      "3 Validation Accuracy: 0.9778\n",
      "4 Validation Accuracy: 0.9746\n",
      "5 Validation Accuracy: 0.9804\n",
      "6 Validation Accuracy: 0.9812\n",
      "7 Validation Accuracy: 0.9796\n",
      "8 Validation Accuracy: 0.9816\n",
      "9 Validation Accuracy: 0.9814\n",
      "10 Validation Accuracy: 0.9832\n",
      "11 Validation Accuracy: 0.9846\n",
      "12 Validation Accuracy: 0.9812\n",
      "13 Validation Accuracy: 0.984\n",
      "14 Validation Accuracy: 0.9834\n",
      "15 Validation Accuracy: 0.9842\n",
      "16 Validation Accuracy: 0.9842\n",
      "17 Validation Accuracy: 0.9836\n",
      "18 Validation Accuracy: 0.984\n",
      "19 Validation Accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation Accuracy:\", acc_valid)\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
